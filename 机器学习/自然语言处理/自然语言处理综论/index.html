<!DOCTYPE html>
<html lang="en">

<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8">
	<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
	
	<!-- title -->
	
	<title>
	
		《自然语言处理综论》学习笔记 | 
	 
	zYx.Tom的个人博客
	</title>
	
	<!-- keywords,description -->
	
		<meta name="keywords" content="工作笔记, 图像处理, 图形处理, Python, PyTorch, Ubuntu, Git, 开发工具, AI, 人工智能, 神经网络" />
	
	
		<meta name="description" content="湖南大学92级本科，浙江大学99级硕士，电子科技大学09级博士。具备2D图像、3D图形方面的AI研究和产品落地能力。" />
	

	<!-- favicon -->
	
	<link rel="shortcut icon" href="/images/avatar.png">
	


	<!-- search -->
	<script>
		var searchEngine = "https://www.baidu.com/s?wd=";
		if(typeof searchEngine == "undefined" || searchEngine == null || searchEngine == ""){
			searchEngine = "https://www.google.com/search?q=";
		}
		var homeHost = "zhuyuanxiang.github.io";
		if(typeof homeHost == "undefined" || homeHost == null || homeHost == ""){
			homeHost = window.location.host;
		}
	</script>


	
<link rel="stylesheet" href="/css/main.css">

	
<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css">

	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/styles/darcula.min.css">

	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">


	
<script src="https://cdn.jsdelivr.net/npm/jquery@3.7.0/dist/jquery.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/highlight.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/npm/jquery-pjax@2.0.1/jquery.pjax.min.js"></script>

	
<script src="/js/main.js"></script>


	
		
<script src="https://cdn.jsdelivr.net/npm/leancloud-storage/dist/av-min.js"></script>

		
<script src="https://cdn.jsdelivr.net/npm/valine@v1.5.1/dist/Valine.min.js"></script>

	
	
		<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

<body>
	<header id="header">
    <a id="title" href="/" class="logo">zYx.Tom的个人博客</a>

	<ul id="menu">
    
      <li class="menu-item">
        <a href="/about" class="menu-item-link">About</a>
      </li>
    

    
      <li class="menu-item">
        <a href="/tags" class="menu-item-link">Tags</a>
      </li>
    

    
      <li class="menu-item">
        <a href="/categories" class="menu-item-link">Categories</a>
      </li>
    

    
      
      
        <li class="menu-item">
          <a href='https://weibo.com/ygpfr' class="menu-item-link" target="_blank">
            Weibo
          </a>
        </li>
      
        <li class="menu-item">
          <a href='https://www.douban.com/people/zhuyuanxiang/' class="menu-item-link" target="_blank">
            Douban
          </a>
        </li>
      
        <li class="menu-item">
          <a href='mailto:zhuyuanxiang@gmail.com' class="menu-item-link" target="_blank">
            E-Mail
          </a>
        </li>
      
    
  
    
      <li class="menu-item">
        <a href='https://github.com/zhuyuanxiang' class="menu-item-link" target="_blank">
          <i class="fa fa-github fa-2x"></i>
        </a>
      </li>
    
	</ul>
</header>

	
<div id="sidebar">
	<button id="sidebar-toggle" class="toggle" ><i class="fa fa-arrow-right " aria-hidden="true"></i></button>
	
	<div id="site-toc">
		<input id="search-input" class="search-input" type="search" placeholder="Press Enter to search">
		<div id="tree">
			

			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										bookmarks
									</a>
									
							<ul>
								<li class="file">
									<a href="/bookmarks/%E5%9B%BE%E4%B9%A6%E5%88%97%E8%A1%A8/">
                     
										    待借图书列表
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/bookmarks/%E7%BD%91%E7%AB%99%E5%88%97%E8%A1%A8/">
                     
										    重要网站
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										医学健康
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E5%8C%BB%E5%AD%A6%E5%81%A5%E5%BA%B7/%E4%B8%AD%E5%8C%BB%E5%85%BB%E7%94%9F%E6%88%90%E6%96%B9/">
                     
										    中医养生
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										基础理论
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										数学
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA/%E6%95%B0%E5%AD%A6/%E6%95%B0%E5%AD%A6%E8%A7%A3%E7%9A%84%E5%88%86%E7%B1%BB/">
                     
										    数学解的分类
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										工作日志
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										2020
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2020/2020%E5%B9%B404%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2020 年 04 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2020/2020%E5%B9%B405%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2020 年 05 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2020/2020%E5%B9%B406%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2020 年 06 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2020/2020%E5%B9%B407%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2020 年 07 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2020/2020%E5%B9%B408%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2020 年 08 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2020/2020%E5%B9%B409%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2020 年 09 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2020/2020%E5%B9%B410%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2020 年 10 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2020/2020%E5%B9%B411%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2020 年 11 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2020/2020%E5%B9%B412%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2020 年 12 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										2021
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2021/2021%E5%B9%B401%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2021 年 01 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2021/2021%E5%B9%B402%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2021 年 02 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2021/2021%E5%B9%B403%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2021 年 03 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2021/2021%E5%B9%B404%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2021 年 04 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2021/2021%E5%B9%B405%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2021 年 05 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2021/2021%E5%B9%B406%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2021 年 06 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2021/2021%E5%B9%B407%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2021 年 07 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										2023
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2023/2023%E5%B9%B408%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2023 年 08 月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2023/2023%E5%B9%B409%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2023 年 09月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/2023/2023%E5%B9%B410%E6%9C%88%E6%97%A5%E8%AE%B0/">
                     
										    2023 年 10月日记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										操作系统
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										Linux
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux/Linux%20%E7%89%88%E6%9C%AC%E5%AF%B9%E6%AF%94/">
                     
										    Linux 版本对比
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										Ubuntu
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux/Ubuntu/Squid/">
                     
										    Squid
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux/Ubuntu/Ubuntu-16/">
                     
										    Ubuntu 16使用指南
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux/Ubuntu/Ubuntu-Remote-Desktop/">
                     
										    Ubuntu Remote Services
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux/Ubuntu/Ubuntu-zsh/">
                     
										    Ubuntu的ZSH安装说明
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux/Ubuntu/Ubuntu/">
                     
										    Ubuntu 学习日志
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										NAS
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/NAS/NAS/">
                     
										    小企业的NAS932+的安装过程
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Thunderbot%20911%20%E9%BB%91%E6%AD%A6%E5%A3%AB%20II/">
                     
										    Thunderbot 911 黑武士 II
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										Windows
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows/Beyond-Compare/">
                     
										    Beyond Compare Evaluate 方法
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows/Windows10/">
                     
										    Windows 10 学习日志
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows/Windows7/">
                     
										    Windows 7 学习日志
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Windows/%E7%94%B5%E8%84%91%E7%83%AD%E9%94%AE%E5%86%B2%E7%AA%81%E6%A3%80%E6%B5%8B/">
                     
										    电脑热键冲突检测
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										机器学习
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										开发框架
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/Neuroph%20%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B/">
                     
										    Neuroph 开发过程
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/PyTorch-DataLoader%E5%AD%A6%E4%B9%A0%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93/">
                     
										    PyTorch-DataLoader学习关键点总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/Scikit-Learn%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                     
										    Scikit-Learn学习笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/Tensorflow-and-Keras%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/">
                     
										    Tensorflow-and-Keras使用心得
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										机器学习
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E3%80%8APython%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《Python 数据科学实践指南》读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E3%80%8A%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《实用机器学习》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%9A%84%E6%80%9D%E8%80%83/">
                     
										    《机器学习》的思考
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E3%80%8A%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                     
										    《概率图模型》学习笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E3%80%8A%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《模式识别与机器学习》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《统计学习方法》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										神经网络
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E3%80%8APython%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《Python 神经网络编程》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《神经网络与机器学习》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E5%9F%BA%E4%BA%8E%20Java%20%E8%AF%AD%E8%A8%80%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《神经网络算法与实现-基于 Java 语言》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										自然语言处理
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/Gensim%20%E5%AD%A6%E4%B9%A0%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93/">
                     
										    Gensim 学习关键点总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E3%80%8APython%20%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                     
										    《Python 自然语言处理》学习笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E3%80%8A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                     
										    《自然语言处理》学习笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file active">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%BB%BC%E8%AE%BA/">
                     
										    《自然语言处理综论》学习笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E9%9D%A2%E8%AF%95%E5%B8%B8%E9%97%AE%E9%97%AE%E9%A2%98/">
                     
										    自然语言处理面试常问问题
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										计算机视觉
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										三维图形
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%BD%A2/%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E6%BE%84%E6%B8%85/">
                     
										    3D图形学基本概念澄清
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%BD%A2/%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%BD%A2%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/">
                     
										    3D 相关知识点汇总
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										设计模式
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E3%80%8AHead%20First%20%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《Head First 设计模式》读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E3%80%8A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E3%80%8B%E7%9B%B8%E5%85%B3%E7%B1%BB%E5%9E%8B%E8%AF%BB%E4%B9%A6%E6%80%BB%E7%BB%93/">
                     
										    《设计模式》相关类型读书总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E3%80%8A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E3%80%8B%E8%AF%BB%E4%B9%A6%E5%B0%8F%E7%BB%93/">
                     
										    《设计模式之禅》读书小结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										软件工程
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/Git%20%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/">
                     
										    Git 使用心得
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/Github%E4%B8%8A%E5%86%99Blog/">
                     
										    Github 上写 Blog
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/Gitlab%E5%AE%89%E8%A3%85%E6%96%87%E6%A1%A3/">
                     
										    Gitlab安装文档
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E3%80%8A%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E4%B9%8B%E9%81%93%20Java%20%E7%89%88%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《单元测试之道 Java 版》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E3%80%8A%E6%B5%8B%E8%AF%95%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《测试驱动开发》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E3%80%8A%E9%87%8D%E6%9E%84%E3%80%8B%E7%9A%84%E6%96%B9%E6%B3%95%E5%88%97%E8%A1%A8/">
                     
										    《重构》的方法列表
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E3%80%8A%E9%87%8D%E6%9E%84%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E6%84%9F%E6%83%B3/">
                     
										    《重构》的读书感想
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E3%80%8A%E9%87%8D%E6%9E%84%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《重构》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E3%80%8A%E9%87%8D%E6%9E%84%E3%80%8B%E7%9A%84%E9%87%8D%E7%82%B9%E5%88%97%E8%A1%A8/">
                     
										    《重构》的重点列表
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E3%80%8A%E9%87%8D%E6%9E%84%E4%B8%8E%E6%A8%A1%E5%BC%8F%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《重构与模式》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E4%B8%BB%E8%A6%81%20GitHub%20%E9%A1%B9%E7%9B%AE%E5%88%97%E8%A1%A8/">
                     
										    主要 GitHub 项目列表
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E5%B7%A5%E5%85%B7%E7%9A%84%E6%84%8F%E4%B9%89/">
                     
										    工具的意义
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E9%87%8D%E6%9E%84%E7%9A%84%E6%84%8F%E4%B9%89/">
                     
										    重构的意义
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										软件开发
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/CUDA%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93/">
                     
										    CUDA关键点总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										database
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/database/MySQL%E5%AD%A6%E4%B9%A0%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93/">
                     
										    MySQL学习关键点总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/database/Navicat%E5%AD%A6%E4%B9%A0%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93/">
                     
										    Navicat学习关键点总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										ide
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/ide/Eclipse%20%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/">
                     
										    Eclipse 学习日志
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/ide/PyCharm%E5%AD%A6%E4%B9%A0%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93/">
                     
										    PyCharm学习关键点总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/ide/VSCode%E5%AD%A6%E4%B9%A0%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93/">
                     
										    VSCode学习关键点总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/ide/VSCode%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/">
                     
										    VSCode插件开发
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										java
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/java/HelloHibernate%20%E7%9A%84%E5%88%9B%E5%BB%BA%E8%BF%87%E7%A8%8B/">
                     
										    HelloHibernate 的创建过程
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/java/Maven%20%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/">
                     
										    Maven 学习日志
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										javascript
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/javascript/%E4%B8%80%E6%AC%BENode%E5%A4%9A%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%EF%BC%88NVS%EF%BC%89/">
                     
										    一款Node多版本管理工具（NVS）
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										markdown
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/markdown/Latex%20%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/">
                     
										    Latex 学习日志
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/markdown/Markdown%20%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/">
                     
										     Markdown 学习日志
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/markdown/MathJax%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/">
                     
										    为 minimal-mistakes-jekyll 加入 MathJax 的支持
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/markdown/Obsidian%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%90%E4%BB%A5%E5%8F%8A%E4%B8%8B%E8%BD%BD%E9%93%BE%E6%8E%A5/">
                     
										    Obsidian常用插件推荐以及下载链接
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/markdown/Pandoc%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                     
										    Pandoc 学习笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/markdown/hexo%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/">
                     
										    hexo史上最全搭建教程
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/markdown/%E7%AC%94%E8%AE%B0%E8%BD%AF%E4%BB%B6%E9%80%89%E6%8B%A9/">
                     
										    笔记软件选择
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										python
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/python/Conda%E5%AD%A6%E4%B9%A0%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93/">
                     
										    Conda学习关键点总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/python/Jupyter%20%E5%AD%A6%E4%B9%A0%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93/">
                     
										    Jupyter 学习关键点总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/python/Numpy%20%E5%AD%A6%E4%B9%A0%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93/">
                     
										    Numpy 学习关键点总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/python/Python%20%E5%AD%A6%E4%B9%A0%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93/">
                     
										    Python 学习关键点总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/python/%E3%80%8APython%20Cookbook%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《Python Cookbook》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/python/%E3%80%8APython%20%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《Python 面向对象编程指南》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/python/%E8%87%AA%E5%AD%A6Python%E8%AF%BB%E8%BF%87%E7%9A%84%E4%B9%A6%E6%80%BB%E7%BB%93/">
                     
										    自学 Python 读过的书总结
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/%E3%80%8A%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E4%B8%8E%E5%88%9B%E6%96%B0%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                     
										    《软件开发与创新》的读书笔记
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										正则表达式
									</a>
									
							<ul>
								<li class="file">
									<a href="/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E5%B8%B8%E7%94%A8%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/">
                     
										    常用的正则表达式
                     
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
		</div>
	</div>
</div>

	<!-- 引入正文 -->
	<div id="content" class="content">
		<h1 id="article-title">
	《自然语言处理综论》学习笔记
</h1>

<!-- meta -->
<div class="article-meta">
	

	<span>ZhuYuanxiang</span>
	<span>2019-06-06 00:00:00</span>

  <div id="article-categories">
    
		  <span>Categories：</span>
      
          
              <span>
                  <i class="fa fa-folder" aria-hidden="true">
                  <a href="/categories/自然语言处理/">自然语言处理</a>
                  </i>
                
              </span>
          
      
    

    
		    <span>Tags：</span>
        
            
                <span>
                    <i class="fa fa-tag" aria-hidden="true">
                    <a href="/tags/机器学习/">机器学习</a>
                    </i>
                </span>
            
        
            
                <span>
                    <i class="fa fa-tag" aria-hidden="true">
                    <a href="/tags/数据科学/">数据科学</a>
                    </i>
                </span>
            
        
            
                <span>
                    <i class="fa fa-tag" aria-hidden="true">
                    <a href="/tags/统计学习/">统计学习</a>
                    </i>
                </span>
            
        
            
                <span>
                    <i class="fa fa-tag" aria-hidden="true">
                    <a href="/tags/模式识别/">模式识别</a>
                    </i>
                </span>
            
        
            
                <span>
                    <i class="fa fa-tag" aria-hidden="true">
                    <a href="/tags/贝叶斯方法/">贝叶斯方法</a>
                    </i>
                </span>
            
        
            
                <span>
                    <i class="fa fa-tag" aria-hidden="true">
                    <a href="/tags/自然语言处理/">自然语言处理</a>
                    </i>
                </span>
            
        
    
  </div>

</div>

<!-- content -->
<div id="article-content">
	<h1 id="自然语言处理综论"><a href="#自然语言处理综论" class="headerlink" title="自然语言处理综论"></a>自然语言处理综论</h1><h2 id="Ch01-导论"><a href="#Ch01-导论" class="headerlink" title="Ch01 导论"></a>Ch01 导论</h2><p>会话代理（conversational agents）或者对话系统（dialogue<br>systems）的组成部分：语言输入和语言输出。</p>
<p>语言输入：</p>
<ul>
<li>自动语音识别（automatic speech recognition）</li>
<li>自然语言理解（natural language understanding）</li>
</ul>
<p>语言输出：</p>
<ul>
<li>自然语言生成（natural language generation）</li>
<li>语音合成（speech synthesis）</li>
</ul>
<p>推理（inference）：对于需要抽取嵌入到网页的其他文本中的信息才能回答的那些更加复杂的问题，需要根据已经知道的事实推出结论，或者从多重的信息源或网页中对信息进行综合或摘取。</p>
<p>自然语言理解系统：拼写歧正、语法检查</p>
<h3 id="语音与语言处理中的知识"><a href="#语音与语言处理中的知识" class="headerlink" title="语音与语言处理中的知识"></a>语音与语言处理中的知识</h3><p>语音学（phonetics）：单词是怎样发出音来而成为声音序列的。</p>
<p>音系学（phonology）：每一个声音是怎样在语音学上实现的。</p>
<p>形态学：关于词的有意义的组成成分的知识</p>
<p>句法学：关于词与词之间结构关系的知识。</p>
<p>语义学：关于意义的知识</p>
<ul>
<li>词汇语义学（lexical semantics）：单词的意义</li>
<li>组合语义学（copositional semantics）：单词组合的意义</li>
</ul>
<p>语用学（pragmatic）或对话（dialogue）：关于意义与说话人的目的和意图之间的关系的知识</p>
<p>话语学：关于比一个单独的更大的语言单位的知识。</p>
<h3 id="歧义"><a href="#歧义" class="headerlink" title="歧义"></a>歧义</h3><p>消解（resolve）或者排歧（disambiguation）的模型与算法。</p>
<p>词汇排歧（lexical disambiguation）：</p>
<ul>
<li>词类标注（parts-of-speech tagging）</li>
<li>词义排歧（word sense disambiguation）</li>
</ul>
<p>句法排歧（syntactic disambiguation），也叫语法排歧。</p>
<ul>
<li>概率剖析（probabilistic parsing）</li>
</ul>
<p>言语行为解释（speech act interpretation）</p>
<h3 id="模型和算法"><a href="#模型和算法" class="headerlink" title="模型和算法"></a>模型和算法</h3><p>模型：</p>
<ul>
<li>状态机器（state machine），就是形式模型。形式模型包括：状态、状态之间的转移以及输入表示等等。<ul>
<li>确定的有限状态自动机（deterministic finite-state automata，DFSA）</li>
<li>非确定的有限状态自动机（non-deterministic finite-state automata，NFSA）</li>
<li>有限状态转录机（finite-state transducers，FST）</li>
</ul>
</li>
<li>形式规则系统（formal rule system）<ul>
<li>正则语法（regular grammars）</li>
<li>正则关系（regular relations）</li>
<li>上下文无关语法（context-free grammars）</li>
<li>特征增益语法（feature-augmented grammars）</li>
</ul>
</li>
<li>基于逻辑（logic）的模型<ul>
<li>一阶逻辑（first order logic），即谓词演算（predicate）</li>
<li>λ运算（lambda-calculus）</li>
<li>特征结构（feature structure）</li>
<li>语义基元（semantic primitives）</li>
</ul>
</li>
<li>概率模型（probabilistic models）<ul>
<li>加权自动机（weighted automaton）</li>
<li>隐马尔可夫模型（Hidden Markov Models，HMM）</li>
</ul>
</li>
<li>向量空间模型（vector-space models）</li>
</ul>
<p>算法：</p>
<ul>
<li><p>动态规划（dynamic programming）算法的状态空间搜索（state space search）</p>
<ul>
<li>深度优先搜索（depth-first search）</li>
<li>最佳优先搜索算法（best-first search）</li>
<li>A<em>搜索算法（A</em> search）（Ref：Ch10）</li>
</ul>
</li>
<li><p>分类器（classifiers）和序列模型（sequence models）</p>
<ul>
<li>分类器把一个单独的客体指派到一个单独的类别中</li>
</ul>
</li>
<li><p>决策树（decision trees）</p>
</li>
<li><p>支持向量机（support vector machines）</p>
</li>
<li><p>高斯混合矩阵（Gaussian mixture models）</p>
</li>
<li><p>逻辑回归（logistic regression）</p>
<ul>
<li>序列模型对于一个客体序列进行分类，并将它指派到一个类别序列中</li>
</ul>
</li>
<li><p>期望最大化算法（Expecctation-Maximization，EM）</p>
</li>
<li><p>统计技术</p>
<ul>
<li>交叉验证（cross-validation）</li>
</ul>
</li>
</ul>
<h3 id="语言、思维和理解"><a href="#语言、思维和理解" class="headerlink" title="语言、思维和理解"></a>语言、思维和理解</h3><p>图灵测试（Turing test）</p>
<h3 id="学科现状与近期发展"><a href="#学科现状与近期发展" class="headerlink" title="学科现状与近期发展"></a>学科现状与近期发展</h3><h3 id="语音和语言处理简史"><a href="#语音和语言处理简史" class="headerlink" title="语音和语言处理简史"></a>语音和语言处理简史</h3><p>语言学中的计算语言学（computational linguistics）</p>
<p>计算机科学中的自然语言处理（natural language processing）</p>
<p>电子工程中的语音识别（speech recognition）</p>
<p>心理学中的计算机心理语言学（computational psycholinguistics）</p>
<h3 id="1-7-小结"><a href="#1-7-小结" class="headerlink" title="1.7 小结"></a>1.7 小结</h3><ul>
<li><p>理解语音和语言处理</p>
</li>
<li><p>语音和语言处理技术与音系学、语音学、形态学、句法学、语义学、语用学和话语分析等不同平面上的语言知识的形式模型和形式表示方法存在着依赖关系。使用包括状态机、形式规则系统、逻辑等在内的形式模型以及概率模型。</p>
</li>
<li><p>语音和语言处理的基础是计算机科学、语言学、数学、电子工程和心理学。</p>
</li>
<li><p>语言和思维之间的密切联系使语音和语言处理技术成为了机器智能的一部分。</p>
</li>
<li><p>语音和语言处理的应用已经越来越丰富多彩。</p>
</li>
</ul>
<ol>
<li>词汇处理</li>
</ol>
<h2 id="Ch02-正则表达式-与-自动机"><a href="#Ch02-正则表达式-与-自动机" class="headerlink" title="Ch02 正则表达式 与 自动机"></a>Ch02 正则表达式 与 自动机</h2><p>正则表达式（regular expression）：描述文本序列的标准记录方式。</p>
<h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><p>正则表达式的搜索需要试图搜索的模式（pattern）和被搜索的文本语料库（corpus）。</p>
<h4 id="基本的正则表达式模式"><a href="#基本的正则表达式模式" class="headerlink" title="基本的正则表达式模式"></a>基本的正则表达式模式</h4><p>正则表达式是区分大小写的。</p>
<p>内部有括号的字符符号串表示所匹配的字符是析取（disjunction）的。</p>
<ul>
<li>连字符“-”：表示在某一范围内的任何字符。</li>
<li>脱字符“^”：如果是方括号内使用，表示否定后续的模式，即不出现某些字符；如果在方括号外使用，只表示字符本身。</li>
<li>通配符（wildcard）：点号“.”。表示任何与单个字符（回车符除外）相匹配的字符。点号常常与星号共用。</li>
<li>计数符：<ul>
<li>问号“?”：表示前面一个字符存在或者不存在。</li>
<li>星号“*”：称为“Kleene *”，其直接前面的字符或正则表达式出现零次或者多次。</li>
<li>加号“+”：称为“Kleene +”，其直接前面的字符或正则表达式出现一次或者多次。</li>
<li>大括号“{m,n}”：表示前面的字符至少出现 m 次，至多出现 n 次。</li>
</ul>
</li>
<li>锚号（anchors）：把正则表达式锚在符号串中某个特定位置的特殊字符。<ul>
<li>脱字符“^”：与行的开始相匹配；</li>
<li>美元符“$”：与行的结束相匹配。</li>
<li>“\b”：表示词界；</li>
<li>“\B”：表示非词界。</li>
</ul>
</li>
</ul>
<h4 id="正则表达式的基本算符"><a href="#正则表达式的基本算符" class="headerlink" title="正则表达式的基本算符"></a>正则表达式的基本算符</h4><p>析取符（pipe symbol）“|”：析取算符（disjunction operator）。</p>
<p>圆括号“()”：表示优先关系。</p>
<p>算符优先层级（operator precedence hierarchy）：圆括号＞计数符＞序列与锚＞析取符</p>
<p>贪心模式：正则表达式尽可能与最长的符号串匹配。</p>
<h4 id="正则表达式的简单例子和复杂例子"><a href="#正则表达式的简单例子和复杂例子" class="headerlink" title="正则表达式的简单例子和复杂例子"></a>正则表达式的简单例子和复杂例子</h4><p>例子中的错误：</p>
<ul>
<li>正面错误（false positives）：错误地匹配的字符串</li>
<li>负面错误（false negatives）：错误地遗漏的字符串</li>
</ul>
<p>增加准确率（accuracy）：把正面错误减少到最低限度。</p>
<p>增加覆盖率（coverage）：把负责错误减少到最低限度。</p>
<h4 id="正则表达式的高级算符"><a href="#正则表达式的高级算符" class="headerlink" title="正则表达式的高级算符"></a>正则表达式的高级算符</h4><p>高级算符可以用简单算符来表达，高级算符可以简化表达式的内容，更加方便阅读和理解。</p>
<ul>
<li>\d &#x3D; [0-9]：任何数字字符</li>
<li>\D &#x3D; [^0-9]：任何非数字字符</li>
<li>\w &#x3D; [a-zA-Z0-9_]：任何字母字符、数字字符或者空白字符</li>
<li>\W &#x3D; [^\w]：一个非字母字符、数字字符或者空白字符</li>
<li>\s &#x3D; [ \r \t \n \f]：空白区域（空白字符、制表字符、换行字符、回车字符）</li>
<li>\S &#x3D; [^\s]：非空白区域</li>
</ul>
<h4 id="正则表达式的实际操作"><a href="#正则表达式的实际操作" class="headerlink" title="正则表达式的实际操作"></a>正则表达式的实际操作</h4><p>替换（substitution）</p>
<p>使用数字算符可以参照前面的模式。</p>
<p>数字算符使用数字存储器保存前面的模式，这些数字存储器称为寄存器（registers）。</p>
<h3 id="有限状态自动机（FSA）"><a href="#有限状态自动机（FSA）" class="headerlink" title="有限状态自动机（FSA）"></a>有限状态自动机（FSA）</h3><p>正则表达式：是一种用于文本搜索的元语言。是描述有限状态自动机（Finite-State<br>Automaton，FSA）的一种方法。是刻画正则语言（regular language）的一种方法。</p>
<p>正则语言是形式语言中的一种。正则语言可以使用正则表达式、有限状态自动机和正则语法（regular<br>grammar）进行描述，即三者是等价的。</p>
<p>FSA 是书中计算工作的理论基础，任何析正则表达式都可以使用有限状态自动机来实现 。</p>
<h4 id="FSA-的表示方式"><a href="#FSA-的表示方式" class="headerlink" title="FSA 的表示方式"></a>FSA 的表示方式</h4><p>自动机（automaton），也叫有限自动机、有限状态自动机），能够识别符号串的集合。</p>
<ul>
<li>图表示：结点表示状态，弧表示转移；</li>
<li>状态转移表（state-transition table）表示。</li>
</ul>
<p>自动机需要 5 个参数实现形式化定义：</p>
<ul>
<li>状态的有限集合</li>
<li>有限的输入符号字母表</li>
<li>初始状态</li>
<li>终极状态集合</li>
<li>状态之间的转移函数或者转移矩阵</li>
</ul>
<h4 id="FSA-中的形式语言"><a href="#FSA-中的形式语言" class="headerlink" title="FSA 中的形式语言"></a>FSA 中的形式语言</h4><p>形式语言（formal language）：是一个模型，能够而且只能够生成或者识别某一形式语言的符号串，这种形式语言的符号串需要满足形式语言的定义的要求。</p>
<p>形式语言是符号串的集合，而每一个符号串由字母表（alphabet）的有限的符号的集合组合而成。基于形式语言定义的自动机可以在封闭的形式中表示无限的集合。</p>
<p>生成语法（generative grammar）：表示形式语言的语法，即自动机定义的能够生成一切可能的符号串的语言。</p>
<h4 id="非确定的-FSA（NFSA）"><a href="#非确定的-FSA（NFSA）" class="headerlink" title="非确定的 FSA（NFSA）"></a>非确定的 FSA（NFSA）</h4><p>非确定的有限自动机（Non-deterministic FSA，NFSA），也可以称之为概率的有限自动机（Probabilistic<br>FSA，PFSA），相对应的自动机也可以称之为确定的有限自动机。</p>
<p>NFSA 或 PFSA 存在概率转移（ε- 转移，ε-transition）。</p>
<h4 id="NFSA-接收符号串"><a href="#NFSA-接收符号串" class="headerlink" title="NFSA 接收符号串"></a>NFSA 接收符号串</h4><p>三种非确定问题的解决方案（solution to the problem of non-determinism）：</p>
<ul>
<li>回退（backup）：在选择点做记号，记录位置和状态，当遇到错误的选择时可以回退到选择点，从而试探其他的路径<ul>
<li>在每个选择点上，需要记住所有不同的选择</li>
<li>对于不同的选择，需要存储足够的信息</li>
<li>结点与位置的结合体称为识别算法的搜索状态（search-state）。</li>
<li>自动机的状态称为结点（node）或者机器状态（machine-state）。</li>
</ul>
</li>
<li>前瞻（look-ahead）：在输入中向前看，预测性地判断应该选择哪条路径</li>
<li>并行（parallelism）：在选择点上并行探查每条不同的路径。</li>
</ul>
<h4 id="FSA-识别就是搜索"><a href="#FSA-识别就是搜索" class="headerlink" title="FSA 识别就是搜索"></a>FSA 识别就是搜索</h4><p>状态空间搜索（state-space<br>search）算法：系统地探索自动机中所有可能的路径，从而正确地识别正则语言中的符号串。</p>
<ul>
<li>深度优先搜索（depth-first search）策略，即后进先出（Last In First Out，LIFO）策略。当状态空间是无限的时候，搜索可能永远无法停止。</li>
<li>广度优先搜索（breadth-first search）策略，即先进先出（First In First Out，FIFO）策略</li>
<li>规模较大的问题，更加复杂的搜索技术：动态规划（dynamic programming）（Ref：Ch13）和 A*搜索算法（Ref：Ch10）。</li>
</ul>
<h4 id="DFSA-与-NFSA-之间的关系"><a href="#DFSA-与-NFSA-之间的关系" class="headerlink" title="DFSA 与 NFSA 之间的关系"></a>DFSA 与 NFSA 之间的关系</h4><p>NFSA 与 DFSA 是完全等价的。</p>
<h3 id="正则语言与有限状态自动机"><a href="#正则语言与有限状态自动机" class="headerlink" title="正则语言与有限状态自动机"></a>正则语言与有限状态自动机</h3><p>正则语言的形式化定义。</p>
<p>正则语言的运算。</p>
<p>正则表达式与自动机的等价转换。</p>
<h3 id="2-4-小结"><a href="#2-4-小结" class="headerlink" title="2.4 小结"></a>2.4 小结</h3><ul>
<li><p>正则表达式语言是模式匹配的有力工具。</p>
</li>
<li><p>正则表达式的基本运算包括符号的毗连、符号的析取（[]，|，.）、记数符（*，+，{m,n}）、锚号（^，$）和前于运算符（(，)）。</p>
</li>
<li><p>正则表达式等价有限状态自动机（FSA）。</p>
</li>
<li><p>存储器（\1 和 ()）是一种高级运算，经常作为正则表达式的一部分，但是不能实现为有限自动机。</p>
</li>
<li><p>自动机把形式语言隐含地定义为在任何的词汇（符号集）中自动机所接收的符号串的集合。</p>
</li>
<li><p>确定的自动机（DFSA）的行为完全由它的状态决定。</p>
</li>
<li><p>非确定的自动机（NFSA）的行为有时必须在多条路径之间进行选择。</p>
</li>
<li><p>任何一个 NFSA 都可以转换成为 DFSA。</p>
</li>
<li><p>NFSA 的进程表中搜索下一个状态的顺序决定了搜索策略：</p>
<ul>
<li><p>深度优先或者后进先出（LIFO）策略相当于把进程表看成堆栈；</p>
</li>
<li><p>广度优先或者先进先出（FIFO）策略相当于把进程表看成队列。</p>
</li>
</ul>
</li>
<li><p>任何的正则表达式都可以自动地编译为 NFSA，即可以自动地编译为 DFSA。</p>
</li>
</ul>
<h2 id="Ch03-词-与-转录机"><a href="#Ch03-词-与-转录机" class="headerlink" title="Ch03 词 与 转录机"></a>Ch03 词 与 转录机</h2><p>正词法规则（orthographic rules）</p>
<p>形态规则（morphological rules）</p>
<p>形态剖析（morphological parsing）：把单词剖析为多个词素</p>
<p>剖析产生的结果可以是形态结构、句法结构、语义结构或者话语结构</p>
<p>剖析产生的形式可以是符号串、树或者网络</p>
<p>词干还原（stemming）、词目还原（lemmatization）、词例还原（tokenization）或者单词切分（word<br>segmentation）</p>
<p>计算两个单词在正记法上的相似度：</p>
<p>形态剖析计算相似度；最小编辑距离计算相似度。</p>
<h3 id="英语形态学概观"><a href="#英语形态学概观" class="headerlink" title="英语形态学概观"></a>英语形态学概观</h3><p>形态学：是研究语素（小的意义单位）构成词的方法。</p>
<p>语素（morpheme）：是语言中负荷意义最小的单位。分为词干（stem）和词缀（affix）。</p>
<p>词缀包括：</p>
<ul>
<li><p>前缀（prefix）：位于词干之前</p>
</li>
<li><p>后缀（suffix）：紧接词干之后</p>
</li>
<li><p>中缀（infix）：插入到词干中间</p>
</li>
<li><p>位缀（circumfix）：同时处于词干的前面和后面</p>
</li>
</ul>
<p>语素构成单词的四种方法：</p>
<ul>
<li><p>屈折（inflection）：把词干和一个表示语法的语素结合起来，所形成的单词一般与原来的词干属于同一个词类，还会产生一些如“一致关系”类的语法功能。</p>
</li>
<li><p>派生（derivation）：把词干和一个表示语法的语素结合起来，所形成的单词一般属于不同的词类，产生的新意义经常难于精确地预测</p>
</li>
<li><p>合成（compounding）：把多个词干结合在一起</p>
</li>
<li><p>附着（cliticization）：把一个单词与一个附着成分（clitic）结合起来。附着成分也是一个语素，它的句法作用像一个形式简化了的单词，按照音系学的规则或者正词法的规则附着在其他单词上。</p>
</li>
</ul>
<h4 id="屈折形态学（inflectional-morphology）"><a href="#屈折形态学（inflectional-morphology）" class="headerlink" title="屈折形态学（inflectional morphology）"></a>屈折形态学（inflectional morphology）</h4><p>英语的屈折系统相对简单：只有名词、动词和部分形容词有屈折变化，可能的屈折词缀的数目也相对较少。屈折的能产性（productive）比较高。</p>
<p>英语名词的屈折变化：</p>
<ul>
<li><p>复数（plural）</p>
</li>
<li><p>领属（possessive）</p>
</li>
</ul>
<p>英语动词分类：</p>
<ul>
<li><p>主要动词（main verbs）：eat, sleep, impeach</p>
</li>
<li><p>情态动词（modal verbs）：can, will, should</p>
</li>
<li><p>基础动词（primary verbs）：be, have, do</p>
</li>
</ul>
<p>英语动词的屈折变化：</p>
<ul>
<li><p>规则的屈折动词：</p>
</li>
<li><p>不规则的屈折动词：</p>
</li>
</ul>
<h4 id="派生形态学（derivational-morphology）"><a href="#派生形态学（derivational-morphology）" class="headerlink" title="派生形态学（derivational morphology）"></a>派生形态学（derivational morphology）</h4><p>英语的派生系统相对复杂：通过对动词和形容词的变化产生名词，即名词化（nominalization）。派生的能产性比较低。</p>
<h4 id="附着（cliticization）"><a href="#附着（cliticization）" class="headerlink" title="附着（cliticization）"></a>附着（cliticization）</h4><p>附着成分是处于词缀和单词之间的语言单位。位于单词前面的附着成分称为前附着成分（proclitics），跟在单词后面的附着成分称为后附着成分（enclitics）。</p>
<p>附着成分的音系学功能相当于词缀，一般比较短，也没有重读。</p>
<p>附着成分的句法功能更像一个单词，作用经常相当于代词、冠词、连接词或者动词。</p>
<h4 id="非毗连形态学"><a href="#非毗连形态学" class="headerlink" title="非毗连形态学"></a>非毗连形态学</h4><p>毗连形态学（concatenative morphology）：单词是由彼此毗连的语素构成的符号串。</p>
<p>非毗连形态学（non-concatenative morphology），也称为模板形态学（template<br>morphology）或者词根与模式形态学（root-and-pattern morphology）。</p>
<h4 id="一致关系（agreement）"><a href="#一致关系（agreement）" class="headerlink" title="一致关系（agreement）"></a>一致关系（agreement）</h4><p>数的一致，性的一致。</p>
<h3 id="有限状态形态剖析"><a href="#有限状态形态剖析" class="headerlink" title="有限状态形态剖析"></a>有限状态形态剖析</h3><p>形态剖析器：</p>
<ul>
<li><p>词表（lexicon）：词干和词缀表以及它们的基本信息</p>
</li>
<li><p>形态顺序规则（morphotactics）：关于形态顺序的模型，用于解释在一个词内，语素与语素之间的联系规则。</p>
</li>
<li><p>正词法规则（orthographic rules）：即拼写规则（spelling</p>
<ol>
<li>rules）。当两个语素结合时，拼写变化的规则。</li>
</ol>
</li>
</ul>
<h3 id="有限状态词表的建造"><a href="#有限状态词表的建造" class="headerlink" title="有限状态词表的建造"></a>有限状态词表的建造</h3><p>计算机词表的构造：</p>
<ul>
<li><p>列出语言中的每个词干和词缀</p>
</li>
<li><p>表示出形态顺序规则，即词干和词缀的结合规则</p>
<ul>
<li>基于有限状态自动机为形态顺序规则建模</li>
</ul>
</li>
</ul>
<p>形态识别（morphological<br>recognition）问题：使用 FSA 判断由字母构成的输入符号串是否合法。</p>
<h3 id="有限状态转录机（FST）"><a href="#有限状态转录机（FST）" class="headerlink" title="有限状态转录机（FST）"></a>有限状态转录机（FST）</h3><p>有限状态转录机（Finite-State<br>Transducer，FST）：用来进行两个层之间的映射的自动机，即可以进行两个符号集合之间的映射的有限自动机。</p>
<p>FST 的用途：</p>
<ul>
<li><p>作为识别器（recognizer）：取一对符号串 S1 和 S2 作为输入和输出，如果 S1 作为输入得到输出是 S2，或者 S2 作为输入得到输出是 S1，则识别成功；否则识别失败。</p>
</li>
<li><p>作为生成器（generator）：如果 FST 能够输出一对符号串 S1 和 S2，则输出成功并同时输出这对符号串，否则输出失败。</p>
</li>
<li><p>作为翻译器（translator）：FST 输入符号串 S1，输出符号串 S2</p>
</li>
<li><p>作为关联器（relater）：计算机符号串的两个集合之间的关系</p>
</li>
</ul>
<p>FST 需要 7 个参数定义：</p>
<ul>
<li><p>状态的有限集合 N</p>
</li>
<li><p>对应于输入字母表中的符号的有限集合</p>
</li>
<li><p>对应于输出字母表中的符号的有限集合</p>
</li>
<li><p>初始符号</p>
</li>
<li><p>终极状态的集合</p>
</li>
<li><p>转换函数或者状态之间的转换矩阵</p>
</li>
<li><p>输出函数。对应于每一个状态和输入，给出可能的输出符号串的集合。</p>
</li>
</ul>
<p>FSA 与正则语言同构（isomorphic），FST 与正则关系（regular relation）同构。</p>
<p>正则关系是符号串偶对的集合，作为符号串集合的正则语言的自然扩充。</p>
<h4 id="定序转录机和确定性"><a href="#定序转录机和确定性" class="headerlink" title="定序转录机和确定性"></a>定序转录机和确定性</h4><p>定序转录机（sequential transducer）：是转录机的一个次类，输入是确定的。</p>
<p>后继转录机（subsequential transducer）是定序转录机的泛化。</p>
<p>p- 后继转录机（p-subsequential transducer）：是后继转录机的泛化。</p>
<h3 id="用于形态剖析的有限状态转录机"><a href="#用于形态剖析的有限状态转录机" class="headerlink" title="用于形态剖析的有限状态转录机"></a>用于形态剖析的有限状态转录机</h3><p>有限状态形态学（finite-state<br>morphology）的范式（paradigm），把一个单词表示为词汇层（lexical<br>level）和表层（surface level）之间的对应。</p>
<ul>
<li><p>词汇层：表示组成该词的语素之间的毗连关系</p>
</li>
<li><p>表层：表示该词实际拼写的字母之间的毗连关系。</p>
</li>
</ul>
<h3 id="转录机和正词法规则"><a href="#转录机和正词法规则" class="headerlink" title="转录机和正词法规则"></a>转录机和正词法规则</h3><p>使用正词法规则来处理英语中在语素边界发生拼写变化的问题。</p>
<p>正词法规则可以在转录机上实现。</p>
<h3 id="结合有限状态转录机的词表与规则"><a href="#结合有限状态转录机的词表与规则" class="headerlink" title="结合有限状态转录机的词表与规则"></a>结合有限状态转录机的词表与规则</h3><p>把转录机的词表和规则结合起来进行剖析和生成。</p>
<p>双层形态学结构，即能用于剖析，也能用于生成。</p>
<p>词表转录机把表示词干和形态特征的词汇层面映射于表示语素简单毗连的中间层面。</p>
<p>若干个正词法转录机并行地运行各种不同的拼写规则。</p>
<p>有限状态转录机从词汇带子生成表层带子时，或者从表层带子剖析词汇带子时，都可以使用带有同样状态序列的同样的层叠式转录机。</p>
<p>剖析比生成要复杂一些，因为在剖析中存在歧义的问题，而排歧需要某些外部的证据。</p>
<p>运行层叠式转录机时，可以通过组合（composing）和交合（intersecting）转录机的方式使之更加有效。</p>
<h3 id="Porter-词干处理器（不使用词表）"><a href="#Porter-词干处理器（不使用词表）" class="headerlink" title="Porter 词干处理器（不使用词表）"></a>Porter 词干处理器（不使用词表）</h3><p>形态剖析的标准算法：使用词表加规则的方法来建立转录机。缺点是需要大规模的联机词表。</p>
<p>Porter 词干处理器是相对简单的算法，可以应用于信息检索中。（Ref：Ch23）</p>
<h3 id="单词和句子的词例还原"><a href="#单词和句子的词例还原" class="headerlink" title="单词和句子的词例还原"></a>单词和句子的词例还原</h3><p>词例还原（tokenization）：把文本切分成单词和句子。</p>
<ul>
<li><p>单词切分（word segmentation）</p>
</li>
<li><p>句子切分（sentence segmentation）</p>
</li>
</ul>
<h4 id="中文的自动切词"><a href="#中文的自动切词" class="headerlink" title="中文的自动切词"></a>中文的自动切词</h4><p>中文切分算法：最大匹配算法（maximum<br>matching，maxmatch），是一种贪心搜索算法，作为基准算法，需要配备一部语言的词典（词表）。缺陷在处理未知词或者未知组合时。</p>
<h3 id="拼写错误的检查与更正"><a href="#拼写错误的检查与更正" class="headerlink" title="拼写错误的检查与更正"></a>拼写错误的检查与更正</h3><p>拼写错误更正的标准算法是概率算法。</p>
<p>拼写错误的检查和更正分解为三大问题：</p>
<ul>
<li><p>非词错误检查（non-word error detection）：检查会导致非词的拼写错误。</p>
</li>
<li><p>孤立词错误更正（isolated-word error correction）：更正会导致非词的拼写错误。</p>
</li>
<li><p>依赖于上下文的错误检查和更正（context-dependent error detection and</p>
<ol>
<li>correction）：如果错误的拼写恰好是一个英语中真实存在的单词，就需要使用上下文来检查和更正这样的拼写错误。</li>
</ol>
</li>
</ul>
<p>有限状态形态剖析器提供了实现大规模词典的技术手段。对于每个单词都可以给出形态剖析，因此 FST 剖析器在本质上就是单词的识别器。如果使用投影操作把 FST 下侧的语言图抽取出来，那么 FST 形态剖析器就可以转化为有效的 FSA 单词识别器。FST 词典就会表示那些能产性的形态变化。</p>
<p>最小编辑距离算法用于计算来源和表层错误之间的距离。</p>
<h3 id="最小编辑距离（minimum-edit-distance）"><a href="#最小编辑距离（minimum-edit-distance）" class="headerlink" title="最小编辑距离（minimum edit distance）"></a>最小编辑距离（minimum edit distance）</h3><p>字符串距离（string<br>distance）：两个符号串之间的距离是这两个符号串彼此相似程度的度量。</p>
<p>最小编辑距离是符号串距离算法的基础，说明了两个符号串之间对齐的情况。</p>
<p>Levenshtein 距离是加权的最小编辑距离。</p>
<p>最小编辑距离使用动态规划进行计算。</p>
<p>最小编辑距离算法可以用来做两个符号串之间的最小代价对齐（alignment）。</p>
<h3 id="人的形态处理方式"><a href="#人的形态处理方式" class="headerlink" title="人的形态处理方式"></a>人的形态处理方式</h3><p>完全枚举法（full<br>listing）：假定人的心理词表中，不管单词内部形态结构如何，只会把语言中的全部单词都一一枚举出来。形态结构只是一种没有因果关系的现象。</p>
<p>最小羡余法（minimum<br>redundancy）：假定人的心理词表中，只表示那些有组合能力的语素，因此当处理单词中必须把与单词相关的所有语素组成起来。</p>
<h3 id="3-13-小结"><a href="#3-13-小结" class="headerlink" title="3.13 小结"></a>3.13 小结</h3><ul>
<li><p>形态剖析是发现在词中所包含的连续的语素的过程</p>
</li>
<li><p>英语主要使用前缀和后缀来表示屈折形态和派生形态</p>
</li>
<li><p>英语的屈折形态比较简单，包括：人称和数的一致关系以及时态标志</p>
</li>
<li><p>英语的派生形态比较复杂，包括：前缀和后缀</p>
</li>
<li><p>英语的形态顺序规则（可容许的语素的顺序）可以用有限自动机来表示</p>
</li>
<li><p>有限状态转录机是能生成输出符号的有限自动机的扩充。FST 的重要运算包括：组合、投影和交运算</p>
</li>
<li><p>有限状态形态学和双层形态学是有限状态转录机在形态表示和剖析中的应用</p>
</li>
<li><p>转录机的自动编译程序是存在的，并且对于任何简单的重写规则都能够选出一个转录机。词表和拼写规则可以通过组合和交合不同的转录机的方式结合起来</p>
</li>
<li><p>Porter 算法是词干还原的简单方法，可以帮助词干剥离词缀。没有包含了词表的转录机那么精确，但是可以应用在不需要做精确形态剖析的工作中，例如：信息检索</p>
</li>
<li><p>单词的词例还原可以使用简单的正则表达式替换或者使用转录机来实现</p>
</li>
<li><p>拼写错误检查通常可以通过发现那些没有在词典中出现的单词的办法来实现；为此可以使用 FST 的词典</p>
</li>
<li><p>两个符号串之间的最小编辑距离是把一个符号串编辑为另一个符号串时所需要的最少的操作次数。最小编辑距离可以使用动态规划的方法来计算结果，也可以用来作两个符号串的对齐。</p>
</li>
</ul>
<h2 id="Ch04-N-元语法"><a href="#Ch04-N-元语法" class="headerlink" title="Ch04 N 元语法"></a>Ch04 N 元语法</h2><p>N 元语法模型（N-gram model）是概率模型。</p>
<p>2 元语法（bigram）是包含 2 个单词的序列；</p>
<p>3 元语法（trigram）是包含 3 个单词的序列；</p>
<p>语言模型（Language Models，LM）是单词序列的概率模型。</p>
<h3 id="语料库中单词数目的计算"><a href="#语料库中单词数目的计算" class="headerlink" title="语料库中单词数目的计算"></a>语料库中单词数目的计算</h3><p>自然语言中统计计算需要依赖于语料库（单数：corpus，复数：corpora）。</p>
<p>语料库是计算机可读的文本或者口语的集合体。</p>
<p>阻断（disfluencies）：切断和有声停顿。</p>
<p>切断（fragment）：一个单词在中间被拦腰切开就形成切断。</p>
<p>有声停顿（filled pauses）：也称为过滤成分（filters）。单词的停顿。</p>
<p>词目（lemma）：具有相同的词干和相同的词义并且主要的词类也相同的词汇形式</p>
<p>词形（wordform）：是一个单词的全部的屈折或者派生形式。</p>
<p>语言的“型”（type）和“例”（token）。“型”就是语料库中不同单词的数目，或者是词汇容量的大小，记为 V；“例”就是使用中的全部单词数目，记为 N。</p>
<h3 id="简单的（非平滑的）N-元语法"><a href="#简单的（非平滑的）N-元语法" class="headerlink" title="简单的（非平滑的）N 元语法"></a>简单的（非平滑的）N 元语法</h3><p>计算某个单词的概率，只考虑最接近该单词的若干个单词，近似地逼近该单词的历史，这是 N 元语法模型的直觉解释。</p>
<p>一个单词的概率只依赖于它前面单词的概率的这种假设称为马尔可夫假设（Markov<br>assumption）</p>
<p>使用最大似然估计（Maximum Likelihood Estimation，MLE）估计 N 元语法模型的概率。</p>
<p>从语料库中得到的计数加以归一化（normalize）。</p>
<p>用前面符号串（prefix）的观察频率来除这个特定单词序列的观察频率，就得到 N 元语法概率的估计值，这个比值称为相对频率（relative frequency）。</p>
<h3 id="训练集与测试集"><a href="#训练集与测试集" class="headerlink" title="训练集与测试集"></a>训练集与测试集</h3><p>训练集（training set）或者训练语料库（training corpus）：</p>
<p>测试集（test set）或者测试语料库（test corpus）：</p>
<p>保留集（held-out set）</p>
<p>初始的测试集又称为调试测试集，又称为开发集（development test set，devset）。</p>
<p>在一些数据上训练，在另一些数据止测试，还可以用来评估不同 N 元语料的总体结构。</p>
<h4 id="N-元语法及其对训练语料库的敏感性"><a href="#N-元语法及其对训练语料库的敏感性" class="headerlink" title="N 元语法及其对训练语料库的敏感性"></a>N 元语法及其对训练语料库的敏感性</h4><p>确保训练语料库与测试语料库有相似性。</p>
<h4 id="未知词：开放词汇和封闭词汇"><a href="#未知词：开放词汇和封闭词汇" class="headerlink" title="未知词：开放词汇和封闭词汇"></a>未知词：开放词汇和封闭词汇</h4><p>未知词（unknown words），或者表外词（Out Of Vocabulary，OOV），没有在系统中看到的单词。</p>
<p>在测试集中出现的表外词 OOV 的百分比称为表外词率（OOV rate）。</p>
<p>在封闭词汇（closed vocabulary）系统中，假定不存在未知词。</p>
<p>在开放词汇（open vocabulary）系统中，给测试集加上一个伪词（pseudo-word）来给这些潜在的未知词建模，这个未知词的模型称为：<code>&lt;UNK\&gt;</code>。</p>
<h3 id="N-元语法的评测：困惑度"><a href="#N-元语法的评测：困惑度" class="headerlink" title="N 元语法的评测：困惑度"></a>N 元语法的评测：困惑度</h3><p>端到端（end-to-end）的评测称为外在评测（extrinsic evaluation），也称为现实评测（in vivo evaluation）或者叫体内评测，将语言模型嵌入到某种应用中，并测试这个应用的总体性能。</p>
<p>内在评测（intrinsic evaluation）：的度量就是一种与任何应用无关的模型质量的评测方法。</p>
<p>困惑度（perplexity，PP）：是对于 N 元语法模型的一种最常见的内在评测的度量指标。困惑度可以用来快速地检验算法，困惑度的改进也可以由端对端的评测来加以确认。</p>
<p>在一个测试集上语言模型的困惑度是该语言模型指派给测试集的概率的函数。</p>
<p>对于测试集，困惑度就是用单词数归一化之后的测试集的概率。</p>
<p>语言的加权平均转移因子（weighted average branching factor）是语言中的任何一个单词后面可能接续的单词的数目。</p>
<h3 id="N-元语法的平滑算法"><a href="#N-元语法的平滑算法" class="headerlink" title="N 元语法的平滑算法"></a>N 元语法的平滑算法</h3><p>最大似然估计过程的主要问题就是训练 N 元语法的参数，而最大似然估计是建立在特定的训练数据集上，因此会产生数据稀疏（sparse data）问题。</p>
<p>“平滑”（smoothing）是用来填补零计数的概率导致的概率计算问题。</p>
<h4 id="Laplace-平滑"><a href="#Laplace-平滑" class="headerlink" title="Laplace 平滑"></a>Laplace 平滑</h4><p>Laplace 平滑（smoothing）或 Laplace 定律（law）：也称为加一平滑（add-one<br>smoothing）。取语法模型的计数矩阵，先把所有的计数加 1，再对概率进行归一化。在实际应用中，效果不是很好。</p>
<h4 id="Good-Turing-打折法"><a href="#Good-Turing-打折法" class="headerlink" title="Good-Turing 打折法"></a>Good-Turing 打折法</h4><p>各种打折算法（Good-Turing 打折法，Witten-Bell 打折法，Kneser-Ney 平滑法）都是利用看过一次的事物的计数来帮助估计从来没有看到过的事物的计数。</p>
<p>只出现过一次的单词或者 N 元语法（或者任何事件）都可以称为单元素（singleton），或者称为罕用语（hapax<br>legomenon），即只出现过一次的单词。</p>
<p>Good-Turing 打折法就是使用单元素的频率作为零计数的一元语法的频率来重新估计概率量的大小。</p>
<h4 id="Good-Turing-估计"><a href="#Good-Turing-估计" class="headerlink" title="Good-Turing 估计"></a>Good-Turing 估计</h4><p>在对 N 元语法进行打折时，不仅使用 Good-Turing 打折法，还需要使用回退和插值算法。</p>
<h3 id="N-元语法的插值法"><a href="#N-元语法的插值法" class="headerlink" title="N 元语法的插值法"></a>N 元语法的插值法</h3><p>使用“有层次”的 N 元语法的两种途径：</p>
<ul>
<li>回退法（back off）：当高阶语法计数存在零概率值时，就回退到低阶的 N 元语法中，使用非零概率值进行计算。</li>
<li>插值法（interpolation）：把所有的 N 元语法估计中的概率值混合起来，即一元语法、二元语法、……、N 元语法的计数进行加权插值。</li>
</ul>
<h3 id="N-元语法的回退法"><a href="#N-元语法的回退法" class="headerlink" title="N 元语法的回退法"></a>N 元语法的回退法</h3><p>Katz 回退法是使用了 Good-Turing 打折法的回退法。</p>
<h3 id="实际问题：工具包和数据格式"><a href="#实际问题：工具包和数据格式" class="headerlink" title="实际问题：工具包和数据格式"></a>实际问题：工具包和数据格式</h3><p>回退 N 元语法模型一般用 ARPA 格式存储。</p>
<p>建立语言模型的工具包：</p>
<ul>
<li><p>SRILM 工具包</p>
</li>
<li><p>Cambridge-CMU 工具包</p>
</li>
</ul>
<h3 id="语言模型建模中的高级专题"><a href="#语言模型建模中的高级专题" class="headerlink" title="语言模型建模中的高级专题"></a>语言模型建模中的高级专题</h3><h4 id="Kneser-Ney-平滑法"><a href="#Kneser-Ney-平滑法" class="headerlink" title="Kneser-Ney 平滑法"></a>Kneser-Ney 平滑法</h4><p>Kneser-Ney 平滑法基于绝对折扣（absolute discounting）的打折方法。</p>
<p>Kneser-Ney 打折法使用更加精致的方法分摊回退值，从而提升绝对折扣</p>
<p>Kneser-Ney 算法使用插值的形式比使用回退的形式效果更好。</p>
<h4 id="基于类别的-N-元语法"><a href="#基于类别的-N-元语法" class="headerlink" title="基于类别的 N 元语法"></a>基于类别的 N 元语法</h4><p>基于类别的 N 元语法（class-based N-gram）或聚类 N 元语法（cluster<br>N-gram）是使用单词的类别信息或者聚类信息的 N 元语法的变体。</p>
<p>基于类别的 N 元语法对于处理训练集中的数据稀疏问题效果很好。</p>
<p>IBM 聚类 N 元语法，是一种硬聚类模型；</p>
<h4 id="语言模型的自适应"><a href="#语言模型的自适应" class="headerlink" title="语言模型的自适应"></a>语言模型的自适应</h4><p>语言模型的自适应（adaptation）：当某个领域内只有数量很少的训练数据，但是其他领域又存在大量数据时，就会面临语言模型的自适应问题。可以使用领域之外的大量的数据集进行训练，设法使训练得到的模型与某个领域内的小量数据产生自适应。</p>
<h4 id="长距离信息的使用"><a href="#长距离信息的使用" class="headerlink" title="长距离信息的使用"></a>长距离信息的使用</h4><p>N 元语法建模中，长距离的上下文信息基本没用。为了更好地利用长距离的上下文信息，可以使用隐藏语言模型（cache<br>language model）。</p>
<p>跳跃式的 N 元语法（skip N-grams）：上下文可以“跳跃过”某些中间的单词。</p>
<p>可变长的 N 元语法（variable-length N-gram）。</p>
<p>语言模型中结合语言结构的方法参考基于统计剖析的句法结构的语言模型（Ref：Ch14）</p>
<p>基于对话中言语行为的语言模型（Ref：Ch24）</p>
<h3 id="信息论背景"><a href="#信息论背景" class="headerlink" title="信息论背景"></a>信息论背景</h3><p>困惑度是建立在信息论（information<br>theory）中关于交叉熵（cross-entropy）概念的基础上。</p>
<p>熵（entropy）是信息量的度量。</p>
<ul>
<li><p>可以度量在一个特定的语法中的信息量的多少</p>
</li>
<li><p>可以度量给定语法和给定语言的匹配程度的大小</p>
</li>
<li><p>可以预测一个给定的 N 元语法中下一个单词是什么</p>
</li>
</ul>
<p>计算序列（sequences）的熵。</p>
<p>熵率（entropy rate）：用单词数来除序列的熵所得的值，即每个单词的熵。</p>
<p>平稳（stationary）的随机过程：随着时间的推移，随机过程指派给序列的概率是不变的。</p>
<h4 id="用于比较模型的交叉熵"><a href="#用于比较模型的交叉熵" class="headerlink" title="用于比较模型的交叉熵"></a>用于比较模型的交叉熵</h4><p>交叉熵（cross-entropy）。</p>
<p>单词序列 W 上的模型的困惑度形式地定义为交叉熵的指数。</p>
<h3 id="英语的熵和熵率均衡性"><a href="#英语的熵和熵率均衡性" class="headerlink" title="英语的熵和熵率均衡性"></a>英语的熵和熵率均衡性</h3><p>英语的熵为概率语法试验提供了可靠的下界；英语的熵帮助信息量最大的内容。</p>
<p>计算英语熵值的方法：</p>
<ul>
<li><p>Shannon 计算的是英语中每个字母的熵，熵值偏低；</p>
</li>
<li><p>使用随机模型，在很大的语料库上训练模型，使用很长的英语序列指派对数概率</p>
</li>
</ul>
<h3 id="4-12-小结"><a href="#4-12-小结" class="headerlink" title="4.12 小结"></a>4.12 小结</h3><ul>
<li><p>N 元语法概率是一个单词在前面给定的 N – 1 个单词的条件下的条件概率。</p>
<ul>
<li><p>N 元语法概率可以通过在语料库中简单地计数，并且使之归一化的方法进行计算（最大似然估计 MLE），或者也可以通过更加复杂的算法计算</p>
</li>
<li><p>N 元语法的优点是可以使用丰富的词汇知识</p>
</li>
<li><p>N 元语法的缺点是对训练语料库的依赖太强</p>
</li>
</ul>
</li>
<li><p>平滑算法为 N 元语法概率的估计提供了比最大似然估计更好的解决办法</p>
<ul>
<li>依赖于低阶 N 元语法计数的常用的 N 元语法的平滑算法是回退法和插值法</li>
</ul>
</li>
<li><p>常用的打折算法</p>
<ul>
<li><p>Kneser-Ney 打折法</p>
</li>
<li><p>Witten-Bell 打折法</p>
</li>
<li><p>Good-Turing 打折法</p>
</li>
</ul>
</li>
<li><p>评测 N 元语法的语言模型时，要把语料库分为训练集和测试集两个部分</p>
<ul>
<li><p>训练集用于训练模型，测试集用于评测模型</p>
</li>
<li><p>测试集上语言模型的困惑度用于对不同的语言模型进行比较</p>
</li>
</ul>
</li>
</ul>
<h2 id="Ch05-词类标注"><a href="#Ch05-词类标注" class="headerlink" title="Ch05 词类标注"></a>Ch05 词类标注</h2><p>词类（Part-of-Speech，POS），又称为单词类别（word classes）、形态类别（morphological classes）或者词汇标记（lexical tags）。</p>
<p>词类标注（part-of-speech tagging）：把词类指派给单词。</p>
<p>词类标注的常用方法：</p>
<ul>
<li>基于规则的标注（rule-based tagging）：手写规则</li>
<li>基于统计机器学习模型的标注<ul>
<li>基于 HMM（隐马尔可夫）模型的标注</li>
<li>基于 MEMM（最大熵）模型的标注</li>
</ul>
</li>
<li>基于转换的标注（transformation-based tagging）：是基于规则的标注与基于统计机器学习模型的的结合</li>
<li>基于记忆的标注（memory-based tagging）</li>
</ul>
<h3 id="英语词的分类"><a href="#英语词的分类" class="headerlink" title="英语词的分类"></a>英语词的分类</h3><ul>
<li>封闭类（closed class）：包含的单词成员相对固定的词类，封闭类的单词又称为虚词（function words）。<ul>
<li>介词（prepositions）：语义上表示关系。通常是空间或时间的关系。On, under, over, near, by, at, from, to, with</li>
<li>限定词（determiners）：与名词一起出现，常常作为名词短语开始的标记。a, an, the</li>
<li>冠词（article）</li>
<li>无定冠词：a, an</li>
<li>有定冠词：the（有定性（definiteness）是话语和语义的一个特性）</li>
<li>代词（pronouns）：she, who, I, others</li>
<li>连接词（conjunctions）：用来连接两个短语、分句或者句子。and, but, or, as, if, when</li>
<li>并列连接词（coordinating conjunction）：连接地位平等的两个成分</li>
<li>助动词（auxiliary verbs）：can, may, should, are</li>
<li>系动词（copula）：be, do, have</li>
<li>情态动词（modal verb）：</li>
<li>小品词（particles）：与动词结合起来一起使用，把意义加以扩展。up, down, on, off, in, out, at, by</li>
<li>短语动词（phrasal verb）：动词与小品词结合形成一个独立的句法或者语义单位的组合。</li>
<li>数词（numerals）：one, two, three, first, second, third</li>
<li>叹词（interjections）</li>
<li>否定词（negatives）</li>
<li>礼貌标志词（politeness markers）</li>
<li>问候词（greetings）</li>
<li>表示存在的 there</li>
</ul>
</li>
<li>开放类（open class）：包含的单词成员经常变化。<ul>
<li>名词（nouns）</li>
<li>专有名词（proper noun）</li>
<li>普通名词（common noun）<ul>
<li>可数名词（count noun）</li>
<li>物质名词（mass noun）</li>
</ul>
</li>
<li>动词（verbs）</li>
<li>形容词（adjectives）</li>
<li>副词（adverbs）<ul>
<li>方位副词（directional adverbs）或地点副词（locative adverbs）：说明某个行为的方向或地点</li>
<li>程度副词（degree adverbs）：说明某个动作、过程或性质延伸的程度</li>
<li>方式副词（manner adverbs）：描述某个行为或者过程的方式</li>
<li>时间副词（temporal adverbs）：描述某个行为或者事件发生的时间</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="英语的标记集"><a href="#英语的标记集" class="headerlink" title="英语的标记集"></a>英语的标记集</h3><ul>
<li>Brown 语料库的 87 个标记</li>
<li>Penn Treebank 的 45 个标记，是小型标记集</li>
<li>CLAWS 的 C5 标记集，61 个标记，是中型标记集</li>
</ul>
<h3 id="词类标注"><a href="#词类标注" class="headerlink" title="词类标注"></a>词类标注</h3><p>词类标注（Part-of-speech tagging，POS tagging）简称为标注（tagging），给语料中的每一个单词指派一个词类或者其他句法类别标记的过程。</p>
<p>先进行词例还原，才可以完成词类标注，词类标注的困难就是歧义消解（ambiguity resolve）。</p>
<h3 id="基于规则的词类标注算法"><a href="#基于规则的词类标注算法" class="headerlink" title="基于规则的词类标注算法"></a>基于规则的词类标注算法</h3><p>词类自动标注算法使用两阶段的体系结构：</p>
<ul>
<li>使用一部词典给每一个单词指派一个潜在的词类表；</li>
<li>使用一个手工书写的排歧规则筛选原来的潜在词类表，使每个单词得到一个单独的词类标记。</li>
</ul>
<p>EngCG 标注算法（EngCG tagger）是最全面的基于规则的词类标注算法，是使用约束语法的方法。EngCG 中的词典 ENGTWOL 是建立在双层形态学（Ref：Ch3）基础上的</p>
<h3 id="基于-HMM-模型的词类标注算法"><a href="#基于-HMM-模型的词类标注算法" class="headerlink" title="基于 HMM 模型的词类标注算法"></a>基于 HMM 模型的词类标注算法</h3><h3 id="基于转换的词类标注算法"><a href="#基于转换的词类标注算法" class="headerlink" title="基于转换的词类标注算法"></a>基于转换的词类标注算法</h3><h3 id="评测和错误分析"><a href="#评测和错误分析" class="headerlink" title="评测和错误分析"></a>评测和错误分析</h3><h3 id="词类标注中的高级专题"><a href="#词类标注中的高级专题" class="headerlink" title="词类标注中的高级专题"></a>词类标注中的高级专题</h3><h3 id="拼写中的噪声信道模型"><a href="#拼写中的噪声信道模型" class="headerlink" title="拼写中的噪声信道模型"></a>拼写中的噪声信道模型</h3><h3 id="5-10-小结"><a href="#5-10-小结" class="headerlink" title="5.10 小结"></a>5.10 小结</h3><h2 id="Ch06-HMM-与-MEMM"><a href="#Ch06-HMM-与-MEMM" class="headerlink" title="Ch06 HMM 与 MEMM"></a>Ch06 HMM 与 MEMM</h2><h3 id="马尔可夫链"><a href="#马尔可夫链" class="headerlink" title="马尔可夫链"></a>马尔可夫链</h3><h3 id="隐马尔可夫模型（HMM）"><a href="#隐马尔可夫模型（HMM）" class="headerlink" title="隐马尔可夫模型（HMM）"></a>隐马尔可夫模型（HMM）</h3><h3 id="似然度的计算：向前算法"><a href="#似然度的计算：向前算法" class="headerlink" title="似然度的计算：向前算法"></a>似然度的计算：向前算法</h3><h3 id="解码：Viterbi-算法"><a href="#解码：Viterbi-算法" class="headerlink" title="解码：Viterbi 算法"></a>解码：Viterbi 算法</h3><h3 id="HMM-的训练：向前——向后算法"><a href="#HMM-的训练：向前——向后算法" class="headerlink" title="HMM 的训练：向前——向后算法"></a>HMM 的训练：向前——向后算法</h3><h3 id="最大熵模型的背景知识"><a href="#最大熵模型的背景知识" class="headerlink" title="最大熵模型的背景知识"></a>最大熵模型的背景知识</h3><h4 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h4><h4 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h4><h4 id="逻辑回归（分类）"><a href="#逻辑回归（分类）" class="headerlink" title="逻辑回归（分类）"></a>逻辑回归（分类）</h4><h4 id="逻辑回归（训练）"><a href="#逻辑回归（训练）" class="headerlink" title="逻辑回归（训练）"></a>逻辑回归（训练）</h4><h3 id="最大熵模型（MEMM）"><a href="#最大熵模型（MEMM）" class="headerlink" title="最大熵模型（MEMM）"></a>最大熵模型（MEMM）</h3><h3 id="6-9-小结"><a href="#6-9-小结" class="headerlink" title="6.9 小结"></a>6.9 小结</h3><ol>
<li>语音处理</li>
</ol>
<h2 id="Ch07-语音学"><a href="#Ch07-语音学" class="headerlink" title="Ch07 语音学"></a>Ch07 语音学</h2><h3 id="言语语音和语音标音法"><a href="#言语语音和语音标音法" class="headerlink" title="言语语音和语音标音法"></a>言语语音和语音标音法</h3><h3 id="发音语音学"><a href="#发音语音学" class="headerlink" title="发音语音学"></a>发音语音学</h3><h3 id="单位范畴与发音变异"><a href="#单位范畴与发音变异" class="headerlink" title="单位范畴与发音变异"></a>单位范畴与发音变异</h3><h3 id="声学语音学和信号"><a href="#声学语音学和信号" class="headerlink" title="声学语音学和信号"></a>声学语音学和信号</h3><h3 id="语音资源"><a href="#语音资源" class="headerlink" title="语音资源"></a>语音资源</h3><h3 id="发音音系学与姿态音系学"><a href="#发音音系学与姿态音系学" class="headerlink" title="发音音系学与姿态音系学"></a>发音音系学与姿态音系学</h3><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><h2 id="语音合成"><a href="#语音合成" class="headerlink" title="语音合成"></a>语音合成</h2><h3 id="文本归一化"><a href="#文本归一化" class="headerlink" title="文本归一化"></a>文本归一化</h3><h3 id="语音分析"><a href="#语音分析" class="headerlink" title="语音分析"></a>语音分析</h3><h3 id="韵律分析"><a href="#韵律分析" class="headerlink" title="韵律分析"></a>韵律分析</h3><h3 id="双音子波形合成"><a href="#双音子波形合成" class="headerlink" title="双音子波形合成"></a>双音子波形合成</h3><h3 id="单元选择（波形）合成"><a href="#单元选择（波形）合成" class="headerlink" title="单元选择（波形）合成"></a>单元选择（波形）合成</h3><h3 id="评测"><a href="#评测" class="headerlink" title="评测"></a>评测</h3><h2 id="Ch08-语音自动识别"><a href="#Ch08-语音自动识别" class="headerlink" title="Ch08 语音自动识别"></a>Ch08 语音自动识别</h2><h3 id="语音识别的总体结构"><a href="#语音识别的总体结构" class="headerlink" title="语音识别的总体结构"></a>语音识别的总体结构</h3><h3 id="隐马尔可夫模型应用于语音识别"><a href="#隐马尔可夫模型应用于语音识别" class="headerlink" title="隐马尔可夫模型应用于语音识别"></a>隐马尔可夫模型应用于语音识别</h3><h3 id="特征抽取：MFCC-失量"><a href="#特征抽取：MFCC-失量" class="headerlink" title="特征抽取：MFCC 失量"></a>特征抽取：MFCC 失量</h3><h3 id="声学似然度的计算"><a href="#声学似然度的计算" class="headerlink" title="声学似然度的计算"></a>声学似然度的计算</h3><h3 id="词典和语言模型"><a href="#词典和语言模型" class="headerlink" title="词典和语言模型"></a>词典和语言模型</h3><h3 id="搜索与解码"><a href="#搜索与解码" class="headerlink" title="搜索与解码"></a>搜索与解码</h3><h3 id="嵌入式训练"><a href="#嵌入式训练" class="headerlink" title="嵌入式训练"></a>嵌入式训练</h3><h3 id="评测：词错误率"><a href="#评测：词错误率" class="headerlink" title="评测：词错误率"></a>评测：词错误率</h3><h2 id="Ch09-语音识别：高级专题"><a href="#Ch09-语音识别：高级专题" class="headerlink" title="Ch09 语音识别：高级专题"></a>Ch09 语音识别：高级专题</h2><h3 id="多遍解码：N-最佳表和格"><a href="#多遍解码：N-最佳表和格" class="headerlink" title="多遍解码：N- 最佳表和格"></a>多遍解码：N- 最佳表和格</h3><h3 id="A-解码算法（“栈”解码算法）"><a href="#A-解码算法（“栈”解码算法）" class="headerlink" title="A*解码算法（“栈”解码算法）"></a>A*解码算法（“栈”解码算法）</h3><h3 id="依赖于上下文的声学模型：三音子"><a href="#依赖于上下文的声学模型：三音子" class="headerlink" title="依赖于上下文的声学模型：三音子"></a>依赖于上下文的声学模型：三音子</h3><h3 id="分辨训练"><a href="#分辨训练" class="headerlink" title="分辨训练"></a>分辨训练</h3><h3 id="语音变异的建模"><a href="#语音变异的建模" class="headerlink" title="语音变异的建模"></a>语音变异的建模</h3><h3 id="元数据：边界、标点符号和不流利的现象"><a href="#元数据：边界、标点符号和不流利的现象" class="headerlink" title="元数据：边界、标点符号和不流利的现象"></a>元数据：边界、标点符号和不流利的现象</h3><h3 id="人的语音识别"><a href="#人的语音识别" class="headerlink" title="人的语音识别"></a>人的语音识别</h3><h3 id="9-9-小结"><a href="#9-9-小结" class="headerlink" title="9.9 小结"></a>9.9 小结</h3><h2 id="Ch10-计算音系学"><a href="#Ch10-计算音系学" class="headerlink" title="Ch10 计算音系学"></a>Ch10 计算音系学</h2><h3 id="有限状态音系学"><a href="#有限状态音系学" class="headerlink" title="有限状态音系学"></a>有限状态音系学</h3><h3 id="有限状态音系学：高级专题"><a href="#有限状态音系学：高级专题" class="headerlink" title="有限状态音系学：高级专题"></a>有限状态音系学：高级专题</h3><h4 id="元音和谐"><a href="#元音和谐" class="headerlink" title="元音和谐"></a>元音和谐</h4><h4 id="模型式形态学"><a href="#模型式形态学" class="headerlink" title="模型式形态学"></a>模型式形态学</h4><h3 id="计算优先理论"><a href="#计算优先理论" class="headerlink" title="计算优先理论"></a>计算优先理论</h3><h3 id="音节切分"><a href="#音节切分" class="headerlink" title="音节切分"></a>音节切分</h3><h3 id="音位规则和形态规则的机器学习"><a href="#音位规则和形态规则的机器学习" class="headerlink" title="音位规则和形态规则的机器学习"></a>音位规则和形态规则的机器学习</h3><h3 id="10-8-小结"><a href="#10-8-小结" class="headerlink" title="10.8 小结"></a>10.8 小结</h3><ol>
<li>句法处理</li>
</ol>
<h2 id="Ch11-英语的形式语法"><a href="#Ch11-英语的形式语法" class="headerlink" title="Ch11 英语的形式语法"></a>Ch11 英语的形式语法</h2><h3 id="组成性"><a href="#组成性" class="headerlink" title="组成性"></a>组成性</h3><h3 id="上下文无关语法"><a href="#上下文无关语法" class="headerlink" title="上下文无关语法"></a>上下文无关语法</h3><h3 id="英语的一些语法规则"><a href="#英语的一些语法规则" class="headerlink" title="英语的一些语法规则"></a>英语的一些语法规则</h3><h3 id="树库"><a href="#树库" class="headerlink" title="树库"></a>树库</h3><h3 id="语法等价与范式"><a href="#语法等价与范式" class="headerlink" title="语法等价与范式"></a>语法等价与范式</h3><h3 id="有限状态语法和上下文无关语法"><a href="#有限状态语法和上下文无关语法" class="headerlink" title="有限状态语法和上下文无关语法"></a>有限状态语法和上下文无关语法</h3><h3 id="依存语法"><a href="#依存语法" class="headerlink" title="依存语法"></a>依存语法</h3><h3 id="口语的句法"><a href="#口语的句法" class="headerlink" title="口语的句法"></a>口语的句法</h3><h3 id="人的语法处理"><a href="#人的语法处理" class="headerlink" title="人的语法处理"></a>人的语法处理</h3><h3 id="11-6-小结"><a href="#11-6-小结" class="headerlink" title="11.6 小结"></a>11.6 小结</h3><h2 id="Ch12-句法剖析"><a href="#Ch12-句法剖析" class="headerlink" title="Ch12 句法剖析"></a>Ch12 句法剖析</h2><h3 id="剖析就是搜索"><a href="#剖析就是搜索" class="headerlink" title="剖析就是搜索"></a>剖析就是搜索</h3><h3 id="12-2-歧义"><a href="#12-2-歧义" class="headerlink" title="12.2 歧义"></a>12.2 歧义</h3><h3 id="面对歧义的搜索"><a href="#面对歧义的搜索" class="headerlink" title="面对歧义的搜索"></a>面对歧义的搜索</h3><h3 id="动态规划剖析算法"><a href="#动态规划剖析算法" class="headerlink" title="动态规划剖析算法"></a>动态规划剖析算法</h3><h4 id="CKY-剖析"><a href="#CKY-剖析" class="headerlink" title="CKY 剖析"></a>CKY 剖析</h4><h4 id="Early-算法"><a href="#Early-算法" class="headerlink" title="Early 算法"></a>Early 算法</h4><h4 id="线图剖析"><a href="#线图剖析" class="headerlink" title="线图剖析"></a>线图剖析</h4><h3 id="局部剖析"><a href="#局部剖析" class="headerlink" title="局部剖析"></a>局部剖析</h3><h4 id="基于规则的有限状态组块分析"><a href="#基于规则的有限状态组块分析" class="headerlink" title="基于规则的有限状态组块分析"></a>基于规则的有限状态组块分析</h4><h4 id="基于机器学习的组块分析"><a href="#基于机器学习的组块分析" class="headerlink" title="基于机器学习的组块分析"></a>基于机器学习的组块分析</h4><h4 id="组块分析系统的评测"><a href="#组块分析系统的评测" class="headerlink" title="组块分析系统的评测"></a>组块分析系统的评测</h4><h3 id="12-10-小结"><a href="#12-10-小结" class="headerlink" title="12.10 小结"></a>12.10 小结</h3><h2 id="Ch14-统计剖析"><a href="#Ch14-统计剖析" class="headerlink" title="Ch14 统计剖析"></a>Ch14 统计剖析</h2><h3 id="概率上下文无关语法（PCFG）"><a href="#概率上下文无关语法（PCFG）" class="headerlink" title="概率上下文无关语法（PCFG）"></a>概率上下文无关语法（PCFG）</h3><h4 id="PCFG-用于排歧"><a href="#PCFG-用于排歧" class="headerlink" title="PCFG 用于排歧"></a>PCFG 用于排歧</h4><h4 id="PCFG-用于语言建模"><a href="#PCFG-用于语言建模" class="headerlink" title="PCFG 用于语言建模"></a>PCFG 用于语言建模</h4><h3 id="PCFG-的概率-CKY-剖析"><a href="#PCFG-的概率-CKY-剖析" class="headerlink" title="PCFG 的概率 CKY 剖析"></a>PCFG 的概率 CKY 剖析</h3><h3 id="PCFG-的规则的概率的学习"><a href="#PCFG-的规则的概率的学习" class="headerlink" title="PCFG 的规则的概率的学习"></a>PCFG 的规则的概率的学习</h3><h3 id="PCFG-存在的问题"><a href="#PCFG-存在的问题" class="headerlink" title="PCFG 存在的问题"></a>PCFG 存在的问题</h3><h4 id="独立性假设忽略了规则之间的结构依存关系"><a href="#独立性假设忽略了规则之间的结构依存关系" class="headerlink" title="独立性假设忽略了规则之间的结构依存关系"></a>独立性假设忽略了规则之间的结构依存关系</h4><h4 id="缺乏对词汇依存关系的敏感性"><a href="#缺乏对词汇依存关系的敏感性" class="headerlink" title="缺乏对词汇依存关系的敏感性"></a>缺乏对词汇依存关系的敏感性</h4><h3 id="PCFG-的改进：使用分离非终极符号"><a href="#PCFG-的改进：使用分离非终极符号" class="headerlink" title="PCFG 的改进：使用分离非终极符号"></a>PCFG 的改进：使用分离非终极符号</h3><h3 id="概率词汇化的-CFG"><a href="#概率词汇化的-CFG" class="headerlink" title="概率词汇化的 CFG"></a>概率词汇化的 CFG</h3><h4 id="Collins-剖析器"><a href="#Collins-剖析器" class="headerlink" title="Collins 剖析器"></a>Collins 剖析器</h4><h3 id="剖析器的评测"><a href="#剖析器的评测" class="headerlink" title="剖析器的评测"></a>剖析器的评测</h3><h3 id="分辨再排序"><a href="#分辨再排序" class="headerlink" title="分辨再排序"></a>分辨再排序</h3><h3 id="基于剖析器的语言模型"><a href="#基于剖析器的语言模型" class="headerlink" title="基于剖析器的语言模型"></a>基于剖析器的语言模型</h3><h3 id="人的剖析"><a href="#人的剖析" class="headerlink" title="人的剖析"></a>人的剖析</h3><h3 id="14-11-小结"><a href="#14-11-小结" class="headerlink" title="14.11 小结"></a>14.11 小结</h3><h2 id="Ch14-特征-与-合一"><a href="#Ch14-特征-与-合一" class="headerlink" title="Ch14 特征 与 合一"></a>Ch14 特征 与 合一</h2><h3 id="特征结构"><a href="#特征结构" class="headerlink" title="特征结构"></a>特征结构</h3><h3 id="特征结构的合一"><a href="#特征结构的合一" class="headerlink" title="特征结构的合一"></a>特征结构的合一</h3><h3 id="语法中的特征结构"><a href="#语法中的特征结构" class="headerlink" title="语法中的特征结构"></a>语法中的特征结构</h3><h4 id="一致关系"><a href="#一致关系" class="headerlink" title="一致关系"></a>一致关系</h4><h4 id="中心语特征"><a href="#中心语特征" class="headerlink" title="中心语特征"></a>中心语特征</h4><h4 id="次范畴化"><a href="#次范畴化" class="headerlink" title="次范畴化"></a>次范畴化</h4><h4 id="长距离依存关系"><a href="#长距离依存关系" class="headerlink" title="长距离依存关系"></a>长距离依存关系</h4><h3 id="合一的实现"><a href="#合一的实现" class="headerlink" title="合一的实现"></a>合一的实现</h3><h4 id="合一的数据结构"><a href="#合一的数据结构" class="headerlink" title="合一的数据结构"></a>合一的数据结构</h4><h4 id="合一的算法"><a href="#合一的算法" class="headerlink" title="合一的算法"></a>合一的算法</h4><h3 id="带有合一约束的剖析"><a href="#带有合一约束的剖析" class="headerlink" title="带有合一约束的剖析"></a>带有合一约束的剖析</h3><h4 id="Early-剖析器结合合一的剖析"><a href="#Early-剖析器结合合一的剖析" class="headerlink" title="Early 剖析器结合合一的剖析"></a>Early 剖析器结合合一的剖析</h4><h4 id="基于合一的剖析"><a href="#基于合一的剖析" class="headerlink" title="基于合一的剖析"></a>基于合一的剖析</h4><h3 id="类型与继承"><a href="#类型与继承" class="headerlink" title="类型与继承"></a>类型与继承</h3><h3 id="15-7-小结"><a href="#15-7-小结" class="headerlink" title="15.7 小结"></a>15.7 小结</h3><h2 id="Ch16-语言和复杂性"><a href="#Ch16-语言和复杂性" class="headerlink" title="Ch16 语言和复杂性"></a>Ch16 语言和复杂性</h2><hr>
<h3 id="Chomsky-层级"><a href="#Chomsky-层级" class="headerlink" title="Chomsky 层级"></a>Chomsky 层级</h3><h3 id="正则语言的判定"><a href="#正则语言的判定" class="headerlink" title="正则语言的判定"></a>正则语言的判定</h3><h4 id="抽吸引理"><a href="#抽吸引理" class="headerlink" title="抽吸引理"></a>抽吸引理</h4><h3 id="自然语言是上下文无关的吗？"><a href="#自然语言是上下文无关的吗？" class="headerlink" title="自然语言是上下文无关的吗？"></a>自然语言是上下文无关的吗？</h3><h3 id="计算复杂性和人的语言处理"><a href="#计算复杂性和人的语言处理" class="headerlink" title="计算复杂性和人的语言处理"></a>计算复杂性和人的语言处理</h3><h3 id="16-6-小结"><a href="#16-6-小结" class="headerlink" title="16.6 小结"></a>16.6 小结</h3><ol>
<li>语义处理 与 语用处理</li>
</ol>
<h2 id="什么是意义？"><a href="#什么是意义？" class="headerlink" title="什么是意义？"></a>什么是意义？</h2><p>意义表示：形式化结构，通过形式化结构捕捉语言语段的意义。</p>
<p>意义表示语言：指定意义表示的语法和语义框架。</p>
<p>语义分析：创建意义表示，并将其指派经语言输入的过程。</p>
<p>四种常见的意义表示：</p>
<ol>
<li><p>一阶逻辑</p>
</li>
<li><p>语义网络</p>
</li>
<li><p>概念依存</p>
</li>
<li><p>基于框架</p>
</li>
</ol>
<p>本章的重点：句子字面意义的表示。</p>
<h3 id="意义表示的计算要求"><a href="#意义表示的计算要求" class="headerlink" title="意义表示的计算要求"></a>意义表示的计算要求</h3><ul>
<li>为什么需要意义？</li>
</ul>
<p>意义表示能够将句子的意义与现实的世界连接建立起连接关系。</p>
<p>意义表示的最基本要求：即意义表示必须能够用于确定句子意义与我们所知道的世界之间的关系。也就是能够确定意义表示的真实性。</p>
<ul>
<li><p>意义表示有什么用？</p>
</li>
<li><p>意义表示如何处理有歧义的情况？</p>
</li>
</ul>
<p>知识库：</p>
<p>可验证能力：计算机系统需要具备的一种能力，是一种将意义表示所描述的情况与知识库中所建模的世界状态进行比较的能力。</p>
<p>无歧义性：</p>
<p>输入的最终意义表示必须是无歧义的。</p>
<p>模糊性：</p>
<p>规范形式（canonical form）理论：表达同样事情的所有输入应该具有相同的意义表示。</p>
<p>优点：合理地为每个不同提问所蕴涵的命题指派同样的意义，从而保证系统简单。</p>
<p>缺点：使语义分析任务变得更加复杂。</p>
<p>实现：从不同单词的不同用法中选取相同的意义，就可以把同样的意义指派给包括这些单词的短语。</p>
<p>单词具有不同词义，不同单词的某些词义之间具有同义关系。</p>
<p>基于上下文选取正确词义的过程称为词义排歧（word sense<br>disambiguation），或称为词义标注，与词性标注相似。（Ref：Ch19，Ch20）</p>
<p>句子指派意义（Ref：Ch18）</p>
<p>推理：计算机系统根据输入的意义表示以及存储的背景知识做出可靠结论的能力。</p>
<p>即使一些命题在知识库中没有显式的表示，具有推理能力的系统也能通过基于当前已知命题进行逻辑推导的方式对其真假做出判断。</p>
<p>推理过程中需要具备处理变量的能力，从而满足处理语言输入不确定性提及的需要。</p>
<p>表达能力：一个意义表示框架应该具备足够的表达能力来处理各种广泛的题材，能够充分地表达任何有意义的自然语言语段的意义。（Ref：17.3 节将介绍如何使用一阶逻辑来表达意义）</p>
<h3 id="模型论语义学"><a href="#模型论语义学" class="headerlink" title="模型论语义学"></a>模型论语义学</h3><p>模型：是一种形式化结构，用于代表世界事件的特定状态。使用特定意义表示语言的表达式能够被系统地映射为该模型的元素。模型能够表示事物、事物的属性以及事物间关系。</p>
<p>意义表示的词汇：</p>
<ol>
<li><p>非逻辑词汇（non-logical</p>
<ol>
<li>vocabulary）：是开放的名称集合，代表事物、属性以及关系。在各种（意义表示）方案中基于谓词、结点、链接标记或框架槽标记等形式实现。</li>
</ol>
</li>
<li><p>逻辑词汇（logical</p>
<ol>
<li>vocabulary）：是封闭集合，包含符号、运算符、量词、链接等。在意义表示语言中，提供了对表达进行组合的形式化手段。</li>
</ol>
</li>
</ol>
<p>指示（denotation）：非逻辑词汇中的每个元素在模型中的固定且定义明确的对应部分。</p>
<p>解释（interpretation）：一个函数，能够将意义表示中的非逻辑词映射到其在模型中恰当的所指上。</p>
<p>真值条件语义学（truth-conditional<br>semantics）：意义表示中针对约定连接运算符的处理。以组成部分的意义（基于模型参照）及通过参照真值表得到的运算符意义为依据，确定复杂表达式真值的方法。</p>
<p>模型包括：</p>
<p>域：需要表示的应用或事件状态中的事物的集合。</p>
<p>属性：事物的属性的集合。</p>
<p>关系：事物间的关系就是域元素的有序列表集合或“元组”（tuple）集合，这些列表或元组中的域元素都参与了对应关系。属性和关系的表示方法是一种外延式的方法。</p>
<p>例子：P462 图 17.2</p>
<h3 id="一阶逻辑（First-Order-Logic，FOL）"><a href="#一阶逻辑（First-Order-Logic，FOL）" class="headerlink" title="一阶逻辑（First-Order Logic，FOL）"></a>一阶逻辑（First-Order Logic，FOL）</h3><p>一阶逻辑是一种灵活方便、易于理解、可计算处理的知识表示方法。基于模型论语义学，满足可验证性、推理和表达能力的计算基础。</p>
<p>一阶逻辑基础项：</p>
<ol>
<li><p>常量：描述世界的特定事物。</p>
</li>
<li><p>函数：相当于英语中用所属格表示的概念。</p>
</li>
<li><p>变量：使系统具备不指向任何特定已经命名的事物的情况下对事物做出判断并进行推断的能力。</p>
</li>
</ol>
<p>基于引用事物的能力、对事物的事实做出论断的能力，能及把事物相互联系的能力，就可以实现初步的组合表示。通过逻辑连词把更大的组合表示结合在一起。</p>
<p>变量的两种用法：引用特定的匿名事物（存在量词）；引用一个集合中的全部事物（全称量词）。</p>
<p>使用存在量词，必须保证至少有一个替换满足句子为真。</p>
<p>使用全称量词，必须保证所有可能的替换都满足句子为真。</p>
<p>λ表示法：提供一种从具体的 FOL 公式进行抽象的方法，特别适合语义分析。扩充了 FOL 句法。</p>
<p>λ化简（λ-reduction）：一种处理方式，通过将λ表达式用于逻辑项时生成新的 FOL 表达式，新的 FOL 表达式中的形参变量可以由指定的项来绑定。</p>
<p>柯里化（currying）：将多论元谓词转换为一系列单论元谓词的技术。</p>
<p>当在分析树中一个谓词的论元并不都作为谓词的子结点出现时，λ符号提供了一种增量式的收集一个谓词论元的方法。</p>
<p>一阶逻辑（FOL）知识库中的各种事物、属性以及关系的意义通过它们与知识库所建模外界世界中的事物、性质和关系之间的对应关系获得。</p>
<p>对于包含逻辑连词的公式，可以把公式中的成分意义与它们所包含的逻辑连词的意义结合起来，从而解释整个公式的意义。</p>
<p>意义表示语言必须支持推理（inference）或推论。也就是给知识库增加可靠的新命题，或者确定没有包含在知识库中的命题的真假的能力。</p>
<p>取式推理（modus<br>ponens）：FOL 提供的被最广泛实现的推论方法。如果蕴涵规则左手边为真，那么这个规则的右手边也为真。左手边为前提，右手边为结论。（Ref：取式推理的应用在 Ch21）</p>
<p>取式推理的两种典型应用方式：</p>
<p>正向链（forward<br>chaining）：当一个单独的事实加到知识库中的时候，取式推理用这种事实来激发所有可以应用的蕴涵规则。优点：在需要时，有关事实已经表示在知识库中；缺点：所引用或者存储的事实可能永远不被使用。</p>
<p>反向链（backward<br>chaining）：取式推理按照相反的方向来证明特定的命题（亦称为查询）。首先，根据查询是否已经存储在知识库中来判定其是否为真；如果不在知识库中，那么就搜索在知识库中有没有可应用的蕴涵规则。</p>
<p>产生式系统（production<br>system）：在认知模型研究中被大量使用的正向链推理系统，该系统增加了额外的控制知识，用来决定哪些规则需要激发。</p>
<p>常见的推理方法介绍：</p>
<p>正向链：是一种可靠的推理方法。是非完备的推理方法。</p>
<p>反向链：是从查询到已知事实的推理方法。是一种可靠的推理方法，是非完备的推理方法。</p>
<p>向后推理：是从已知结果到未知前提的推理方法。不是一种可靠的推理方法。是一种经常使用、似是而非的推理形式。亦称为诱导法（abduction）或“溯因推理”。</p>
<p>归结法（resolution）：是替换推理技术，是可靠而且完备的。但是计算代价高。</p>
<p>因此，大多数系统还是采用某种链式推理的形式，而把建设系统的主要工作放到用于支持推理的建模知识的开发上。</p>
<h3 id="事件与状态的表示"><a href="#事件与状态的表示" class="headerlink" title="事件与状态的表示"></a>事件与状态的表示</h3><p>事件和状态的表示构成了语言中所需要捕获的大部分语义信息。</p>
<p>状态是在一定时间段内保持不变的状况或属性；</p>
<p>事件则表示一些事务状态的改变。</p>
<p>事件表示方法：</p>
<ol>
<li><p>意义假设（meaning postulates）：存在规模扩展性问题。</p>
</li>
<li><p>同样的谓词：做了太多的假设；缺乏引用问题中特定事件的办法，无法将事件个体化。</p>
</li>
<li><p>Davidsonian 事件表示：增加事件变量作为任何事件表示的第一个论元。必须要为每个谓词确定一组固定的语义角色，接着借助额外的谓词捕获其他辅助的事实。</p>
</li>
<li><p>Neo-Davidsonian 事件表示：</p>
</li>
</ol>
<p>. 1. 对于一个给定的表层谓词，无须预先确定论元的具体数目，不管在输入中出现多少角色和填充项都可以连接到表层谓词上。</p>
<p>. 2. 只要在输入中提到角色，不需要再对角色进行意义假设。</p>
<p>. 3. 在有密切联系的例子之间，只要使用逻辑连接就可以把它们联系起来，无须意义假设。</p>
<h4 id="时间表示"><a href="#时间表示" class="headerlink" title="时间表示"></a>时间表示</h4><p>时序逻辑（temporal logic）：如何用一个有用的形式表示时间信息。</p>
<p>时态逻辑（tense logic）：使用动词时态传达时间信息。（Ref：Ch22<br>时间表达式的表示与分析）</p>
<p>参照点：用于处理背景中隐藏着另外一个没有命名的事件。在简单时间处理方法中，时间流中的当前时刻等于说话的时间这个当前时刻作为事件发生时的参照点（在之前、在当时、在之后）。参照点的概念是与说话时间和事件时间分开的。</p>
<p>参照方法的时间来表示事件的时间。</p>
<h4 id="体"><a href="#体" class="headerlink" title="体"></a>体</h4><p>体（aspect）：涉及相关话题的一个聚类，包括一个事件是否结束，一个事件是否进行，一个事件是发生在一个时间点上还是在一个时间段上，是否世界上的某一个特定状态会由于这个事件的到来而发生。</p>
<p>事件的表示分为 4 个体：</p>
<ul>
<li><p>静态体（Stative）表示：表示事件的参与者在一个给定时间点具有特定的属性，或者处于一个状态之中。即一个单独的时间点上的世界被捕捉的特定侧面。</p>
</li>
<li><p>行动体（Activity）表示：表示参与者所参与的事件，同时该事件没有特定的结束时间点。行动体的行动是发生在时间的某一个片段上。</p>
</li>
<li><p>完成体（Accomplishment）表示：描写的事件有一个自然的结束点，并且导致特定的状态。事件是发生在某个时期之内，当期望状态达到的时候，事件就结束了。</p>
</li>
<li><p>达成体（Achievement）表示：以一个状态为结束，但是事件是立即发生的。</p>
</li>
</ul>
<p>终结体可能事件（telic<br>eventualities）：因为完成体表示与达成体表示的结果都导致特定状态，因此可以结合起来作为一类单独的体。</p>
<h3 id="描述逻辑"><a href="#描述逻辑" class="headerlink" title="描述逻辑"></a>描述逻辑</h3><p>意义表示方法：</p>
<ul>
<li><p>FOL 方法：一阶逻辑方法。（Ref：Sec17.3）</p>
</li>
<li><p>语义网络（semantic</p>
<ol>
<li>networks）：事物用图的结点表示，事物之间的关系用有名字的连接边来表示。</li>
</ol>
</li>
<li><p>框架（frames）方法：也称为槽填充（slot-filler）表示法。在基于框架的系统中，事物用特征结构来表示（Ref：Ch15）或者用图来表示。特征叫做槽，槽的值或者填充值可以用原子值来表示，也可以用另一个嵌套的框架来表示。</p>
</li>
</ul>
<p>以上这些方法表示的意义在原则上都可以转换为等价的 FOL 表示。</p>
<h4 id="描述逻辑-1"><a href="#描述逻辑-1" class="headerlink" title="描述逻辑"></a>描述逻辑</h4><p>描述逻辑是为了更好地理解和说明结构化网络表示的语义，也同时提供了适合于特定类型的领域建模的一种概念框架。描述逻辑是一个方法族，对应 FOL 的一个变化子集。对描述逻辑表达施加的各种限制都为了确保各种重要类型推论的可靠性。使用描述逻辑对某个应用领域进行建模时，着重表达类别、属于类别的个体和个体间的关系这些知识。</p>
<p>构成一个特定应用领域的类别或概念的集合，被称为专业术语（terminology）。</p>
<p>一个知识库中专业术语的部分被称为 TBox；包含关系个体事实的部分被称为 ABox。</p>
<p>专业术语被组织成名为本体知识体系（ontology）的层次结构，用于捕获类别之间包含与被包含的关系。</p>
<p>捕获术语间的层次关系的方法有两种：</p>
<ul>
<li><p>直接声明类别之间的层次化关系；</p>
</li>
<li><p>为概念提供完整的定义，再通过定义来推导层次关系。</p>
</li>
</ul>
<p>描述逻辑中的关系是典型的二元关系，通常被称为角色或角色关系。</p>
<h4 id="逻辑推理"><a href="#逻辑推理" class="headerlink" title="逻辑推理"></a>逻辑推理</h4><p>描述逻辑中的重点在于类别、关系以及个体，是逻辑推理的一个受限子集。</p>
<p>逻辑推理系统包括两个紧密耦合的问题：包含的和实例检验，没有使用 FOL 允许的全套推理。</p>
<p>包含（subsumption）：作为推理的一种形式，是基于专门术语中的事实声明两个概念间是否存在子集∕超集关系的一项决策任务。</p>
<p>实例检验（instance<br>checking）决定一个个体是否是一个特定类别的成员，给定关系这个个体和这个类别的事实。</p>
<p>包含和实例检验隐含的推理机制不仅仅是对专门术语中包含关系的简单检验，而是必须使用专门术语的关系型声明来地推理，以得到适当的包含关系和成员关系。</p>
<p>一个基于基础包含推理的相关推理任务，是在给定专门术语类别事实的条件下获取专门术语的隐含层级结构（impli<br>hierarchy）。</p>
<p>实例检验是判定一个特定个体是否可以被分到一个特定类别的一项任务。</p>
<p>描述逻辑的主要实现技术是建立在可满足性的基础之上，并且依据于基于模型的语义。（Ref：Sec<br>17.2）</p>
<h4 id="Web-本体语言和语义网络"><a href="#Web-本体语言和语义网络" class="headerlink" title="Web 本体语言和语义网络"></a>Web 本体语言和语义网络</h4><p>语义网络：是一种描述网络内部语义的方法。关键部分是对不同应用领域中本体知识的创建与开发。描述逻辑是语义网络开发的一部分。用来表示知识的意义表示语言就是 Web 本体语言（Web<br>Ontology Language，OWL），其本身包含了一种描述逻辑。</p>
<h3 id="意义的具体化-与-情境表示方法"><a href="#意义的具体化-与-情境表示方法" class="headerlink" title="意义的具体化 与 情境表示方法"></a>意义的具体化 与 情境表示方法</h3><p>过程性语义模型：</p>
<p>意义即行动（meaning as<br>action）：话语被看成行动，话语的意义来自于话语导致的行为步骤。</p>
<p>执行图式（executing<br>schema）模型或 X 图式（x-schema）模型：事件语义的各个部分都是基于感知——行动过程的图式描述的。这个模型通过 Petri 网的概率自动机来表示事件在“体”方面的语义。</p>
<p>通过隐喻表示抽象概念，这些隐喻可以在以感知或行动基元为基础的概念间建立联系。</p>
<h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><ul>
<li><p>形式化的意义表示（formal meaning</p>
<ol>
<li>representation）是计算语言学中意义表示的主要方法，用于捕捉与输入内容（语言）有关的意义。目的是实现语言到世界常识之间的映射。</li>
</ol>
</li>
<li><p>意义表示语言（meaning representation</p>
<ol>
<li>language）是说明意义表示的语法和语义的框架。它的各种变体被广泛地应用于自然语言处理和人工智能。</li>
</ol>
</li>
<li><p>意义表示需要能够支持语义处理的计算要求，包括需要确定命题的真值、支持无歧义的表示（unambiguous</p>
<ol>
<li>representations）、表达变量（variables）、支持推理（inference），以及具有充分的描述力（expressive）。</li>
</ol>
</li>
<li><p>人类语言使用特征来传达意义。表达谓词论元结构的能力是最为重要的特征。</p>
</li>
<li><p>一阶逻辑（First-Order</p>
<ol>
<li>Logic，FOL）是一种容易理解的、在计算上可循的意义表示语言。</li>
</ol>
</li>
<li><p>一阶逻辑可以捕获语义表示的重要元素：状态和事件。</p>
</li>
<li><p>一阶逻辑可以表达语义网络和框架。</p>
</li>
<li><p>现代描述逻辑由完整的一阶逻辑中的子集构成，这个子集满足有用的、计算上可处理的要求。</p>
</li>
</ul>
<h2 id="计算语义学"><a href="#计算语义学" class="headerlink" title="计算语义学"></a>计算语义学</h2><p>语义分析（semantic analysis）：将意义表示进行组合并指派给语言表达式的过程。</p>
<p>常用的知识源：词的意义、语法结构所蕴含的常规意义、话语的结构知识、与话题相关的常识以及与话语中事件状态相关的知识。</p>
<p>句法驱动的语义分析（syntax-driven semantic<br>analysis）：在给句子指派意义表示时，仅仅依赖于词典和语法知识。这个意义表示是独立于上下文并与推理无关的表示。</p>
<p>句法驱动的语义分析的作用：简单的表示足以产生有用的结果；简单的表示可以作为后续处理的输入，进而产生更加丰富和更加完整的意义表示。</p>
<p>句法、词法、复指语歧义和量词辖域都可能引起歧义。</p>
<h3 id="句法驱动的语义分析"><a href="#句法驱动的语义分析" class="headerlink" title="句法驱动的语义分析"></a>句法驱动的语义分析</h3><p>组合性原则（principle of<br>compositionality）：句子的意义可以从其组成部分的意义构建而成。</p>
<p>Mad<br>Hatter 给出的原则提示：句子的意义并不仅仅依赖于句中的词汇量，还依赖于句中词汇的顺序、词汇所形成的群组以及词汇间的关系。即：句子的意义部分依赖于句法结构。</p>
<p>图 18.1 用于语义分析的简单的管道流方法：</p>
<p>输入→句法分析器→（句法结构）→语义分析器→输出的语义表示</p>
<p>规则到规则的假设（rule-to-rule hypothesis）：</p>
<h3 id="句法规则的语义扩充"><a href="#句法规则的语义扩充" class="headerlink" title="句法规则的语义扩充"></a>句法规则的语义扩充</h3><p>上下文无关语法规则扩充的语义附着（semantic<br>attachments）。（Ref：Ch15）这些附着是确定如何利用句法结构成分的意义来计算整体意义表示的规则。</p>
<p>使用更加原则性的方法来实例化规则到规则的方法，两种带约束的原则性的方法：</p>
<ol>
<li><p>FOL 和λ算子符号；</p>
</li>
<li><p>基于特征结构以及统一形式方法。</p>
</li>
</ol>
<p>语法规则的语义附着主要由λ化简组成，其中λ表达式的一个元素用作一个算子，其他元素用作算子的论元。</p>
<p>特征结构和合一运算提供了一种有效的方法来实现句法驱动的语义分析。</p>
<h3 id="量词辖域歧义及非确定性"><a href="#量词辖域歧义及非确定性" class="headerlink" title="量词辖域歧义及非确定性"></a>量词辖域歧义及非确定性</h3><p>量词辖域问题：包含量化词的表达式也可能引起歧义。</p>
<p>为了解决量词辖域问题的手段：</p>
<ul>
<li><p>有效创建非确定性表示的能力，该表示需要在不显示枚举所有可能解释的情况下包含它们；</p>
</li>
<li><p>从上述表示中生成或抽取所有可能解释的手段；</p>
</li>
<li><p>对所有可能的解释进行选择的能力。</p>
</li>
</ul>
<h4 id="存储与检索方法"><a href="#存储与检索方法" class="headerlink" title="存储与检索方法"></a>存储与检索方法</h4><p>使用存储替换单独的语义附着。存储包括一个核心的语义表示，以及一个量化表达式的索引列表，这些量化表达式都是从树中该结点的子结点中收集的。</p>
<p>从存储中检索出完全确定的表示所必须的过程。</p>
<p>基于存储的方法存在的两个问题：</p>
<p>只能解决由量化的名词短语引起的辖域歧义问题。</p>
<p>允许枚举给定的表达式所有可能的范围，但是不允许在可能的范围上施加额外的约束。</p>
<h4 id="基于约束的方法"><a href="#基于约束的方法" class="headerlink" title="基于约束的方法"></a>基于约束的方法</h4><p>有效地表示非确定性的表述，以及最终表示必须满足的所有约束。</p>
<p>只要一个完全确定的 FOL 表达式与这些约束一致，那么这个表达式就符合要求。</p>
<p>基于约束的非确定性表示方法：</p>
<p>不特定于语法结构或歧义来源。</p>
<p>支配约束赋予表达约束的能力，这些约束可用于排除不必要的解释。</p>
<h3 id="基于合一的语义分析方法"><a href="#基于合一的语义分析方法" class="headerlink" title="基于合一的语义分析方法"></a>基于合一的语义分析方法</h3><p>将复杂的特征结构与单独的上下文无关语法规则组成对，以此来对诸如数一致关系和次范畴化这样的句法约束进行编码，且这些约束通常无法通过上下文无关语法传递。</p>
<h3 id="语义与-Early-分析器的集成"><a href="#语义与-Early-分析器的集成" class="headerlink" title="语义与 Early 分析器的集成"></a>语义与 Early 分析器的集成</h3><p>基于 Early 分析器可以把语义结合到语法分析中，</p>
<p>优点：在句法处理时就可以考虑语义，从而在生成意义表示时就可以阻塞语义的非良构形式进入线图。</p>
<p>缺点：耗费精力在孤立成分的语义分析上。</p>
<h3 id="成语和组成性"><a href="#成语和组成性" class="headerlink" title="成语和组成性"></a>成语和组成性</h3><p>成语（idiomaticc language）：即习惯用语，或者称为“俗语”。</p>
<p>对于习惯用语的结构，最直接的处理方法就是引入为处理这些习惯用语而特意设计的新语法规则。规则将基于语法成分将词项混合，再引入语义内容，而这个语义内容不是从任何词项中得来的。</p>
<p>处理习惯用语的要求：</p>
<p>允许词典项与传统语法成分的混合；</p>
<p>为了能够处理习惯用语多样性的正确范围，允许生成额外的特定习惯用语的成分；</p>
<p>准许在语义附着引入与规则中的任何成分无关的逻辑项和谓词。</p>
<h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><p>语义分析是生成意义表示，并将这些意义表示指派给语言输入的过程。</p>
<p>语义分析器能够利用词典和语法中的静态知识，生成上下文无关的字面意义或习惯意义。</p>
<p>组合性原则说明一个句子的意义可以由它的组成部分的意义组合而成。</p>
<p>在句法驱动的语义分析中，部分是指输入的一个句法成分。</p>
<p>通过一些符号扩展，例如：λ表达式和复杂项，可以采用组合方式创建 FOL 公式。</p>
<p>基于特征结构和合一算法提供的机制也可以合成 FOL 公式。</p>
<p>自然语言中的量词会带来一种很难通过组合方式处理的歧义。</p>
<p>非确定性表示可以用来处理由辖域歧义引起的多重解释。</p>
<p>成语（习惯用语）问题无法利用组合性原则解决，但是可以采用设计语法规则及其语义附着技术来处理。</p>
<h2 id="词汇语义学"><a href="#词汇语义学" class="headerlink" title="词汇语义学"></a>词汇语义学</h2><p>基于词汇语义学（lexical semantics）建立的词汇语义模型。</p>
<p>词位（lexeme）：表示一个特定形式（正字的或音韵的）及其意义组成的数据对。</p>
<p>词表（lexicon）：由有限个词位组成的表</p>
<p>词目（lemma）或引用形式（citation form）：是用来表示词位的语法形式。</p>
<p>词形（wordforms）：词的具体形式。</p>
<p>词形还原（lemmatization）：从词形到词目的映射过程。</p>
<p>例如：sing, sang, sung 是三个词形，sing 是它们的词目。</p>
<p>词形还原的方法：形态分析算法（Ref：Ch3）</p>
<h3 id="词义"><a href="#词义" class="headerlink" title="词义"></a>词义</h3><p>词义（word<br>sense）或含义：是单词特定意义侧面的离散表示，即表示单词意义的词位的一部分。</p>
<p>词的关系：同形关系（homonymy）、多义关系（polysemy）、同形（同音）异义词（homonyms）、同音异义（homophones）、同形异义（homographs）</p>
<p>同形关系：共享同一个发音和拼写的两个含义的关系。</p>
<ul>
<li>含义间的关系是同形关系的一种，含义间的语义关系是系统化的和结构化的。</li>
</ul>
<p>多义关系：两个含义的语义相关的关系。</p>
<ul>
<li>借喻（metonymy）是多义关系的特定子类型。借喻是使用概念或实体的一个方面来指代这个实体的其他方面和这个实体本身。</li>
</ul>
<p>同音异义关系：具有相同的发音但是词目拼写不同的两个含义之间的关系。</p>
<p>同形异义关系：同一词目但是发音不同的两个含义之间的关系。</p>
<p>共轭搭配法（zeugma）：通过将相反的含义结合在一起来证明某个词目拥有不同含义的方法。</p>
<p>字典中的词义比计算需要的词义更加细粒度，因此计算需要的词义会将字典中的词义进行分组和聚类。</p>
<p>字典中的词义存在着回环（circularity）问题，但是这些词义依然能够帮助人们理解查询的单词。</p>
<p>为了满足计算的需要，词义的定义方法：</p>
<ol>
<li><p>类似于字典中的定义方法，通过目标含义与其他含义间的关系对其进行定义。如：WordNet 中定义的词义关系。</p>
</li>
<li><p>创建一个小规模的有限语义基元组，即意义的原子结构。主要用在定义事件意义时，如：语义角色。</p>
</li>
</ol>
<h3 id="含义间的关系"><a href="#含义间的关系" class="headerlink" title="含义间的关系"></a>含义间的关系</h3><p>以下关系是含义间的关系，而不是词间关系。</p>
<h4 id="同义关系（synonymy）"><a href="#同义关系（synonymy）" class="headerlink" title="同义关系（synonymy）"></a>同义关系（synonymy）</h4><p>同义（synonyms）：两个不同的词（词目）的两个含义相同或者几乎相同。</p>
<p>同义关系：如果两个词在任意一个句子中可以互相替换，并且不影响句子的真值条件，那么这两个词的关系就是同义关系。通常称这两个词有相同的命题意义（propositional<br>meaning）。</p>
<p>同义词是具有相同或者相似意义的词；反义词是具有相反意义的词。</p>
<h4 id="反义关系（antonymy）"><a href="#反义关系（antonymy）" class="headerlink" title="反义关系（antonymy）"></a>反义关系（antonymy）</h4><p>反义（antonyms）：两个不同的词（词目）的两个含义是二元相反值或者位于某个尺度的两个相反的极点上，或者两个含义是完全可逆的，即描述某种反向的改变或者运动。</p>
<p>反义关系：除了相反的意义的某个方面，两个词共享着意义的几乎所有其他方面，因此它们具有非常相似的意义。</p>
<h4 id="上下位关系（hypernymy）"><a href="#上下位关系（hypernymy）" class="headerlink" title="上下位关系（hypernymy）"></a>上下位关系（hypernymy）</h4><p>上位词（hypernym，superordinate）与 下位词（hyponym）。</p>
<p>上位词是下位词的抽象，下位词是上位词的具体；</p>
<p>上位词是下位词的超类，下位词是上位词的子类；</p>
<p>上位词表示的类在外延上包含了下位词表示的类。</p>
<p>如果 A 中的所有对象都是 B 的对象，则称 A 蕴涵（entailment）了 B，即含义 A 是含义 B 的下位词。</p>
<p>本体（ontology）是指对单一领域或微世界（microworld）进行分析而获得的不同客体的集合。（Ref：Ch17）</p>
<p>分类体系（taxonomy）是指把本体知识体系中的元素排列成树状分类结构的一种特别方式。</p>
<p>分类体系是上下位关系的子类型。</p>
<h4 id="语义场（semantic-field）"><a href="#语义场（semantic-field）" class="headerlink" title="语义场（semantic field）"></a>语义场（semantic field）</h4><p>部分——整体（part-whole）关系，称为整体部分关系（meronymy），包括：整体词（holonym）和部分词（meronym）。</p>
<p>同义关系、反义关系和上下位关系都是两个含义之间的二元关系。</p>
<p>语义场是一个针对某个特定领域所有词间的关系集合的更加综合、更加整体的模型。使用的工具有：框架、模型、脚本等。</p>
<p>FrameNet（框架网）提供了一个健壮的框架知识的计算资源。在 FrameNet 表示中，框架中的每个词都针对不同的框架定义，并且与框架中的其他词共享意义的各个方面。</p>
<h3 id="WordNet：词汇关系信息库"><a href="#WordNet：词汇关系信息库" class="headerlink" title="WordNet：词汇关系信息库"></a>WordNet：词汇关系信息库</h3><p>同义集（synset，synonym set）：一个义项的一组近乎同义词；</p>
<p>同义集是 WordNet 的重要的基础性成分。</p>
<p>WordNet 将概念表示为可以用来诠释概念的词义列表。</p>
<p>WordNet 中的根结点被称为独立起始概念（unique beginner）。</p>
<h3 id="事件参与者"><a href="#事件参与者" class="headerlink" title="事件参与者"></a>事件参与者</h3><p>事件论元的两种语义约束：语义角色（semantic roles） 和 选择限制（selectional<br>restrictions）。</p>
<p>题旨角色：特定的语义角色模型。</p>
<h4 id="题旨角色（Thematic-Roles）"><a href="#题旨角色（Thematic-Roles）" class="headerlink" title="题旨角色（Thematic Roles）"></a>题旨角色（Thematic Roles）</h4><p>深层角色特定于不同的事件。</p>
<p>题旨角色试图捕获不同词之间的语义共性。</p>
<p>参与者的题旨角色就是主题（theme）。</p>
<h4 id="因素交替"><a href="#因素交替" class="headerlink" title="因素交替"></a>因素交替</h4><p>题旨角色帮助泛化论元的不同表层实现。</p>
<p>动词支配的题旨角色论元组被称为题旨格（thematic grid）或者θ格或者格框架（case<br>frame）。</p>
<p>多论元结构的实现被称为动词交替（verb alternations）或者因素交替（diathesis<br>alternations）。</p>
<p>与格交替（dative alternations）与动词的特定语义类同时出现。</p>
<h4 id="题旨角色存在的问题"><a href="#题旨角色存在的问题" class="headerlink" title="题旨角色存在的问题"></a>题旨角色存在的问题</h4><p>基于抽象化具体题旨角色的广义语义角色（generalized semantic roles）。</p>
<p>两种基于语义角色的词汇资源为语义角色标注算法提供训练数据：</p>
<ol>
<li><p>命题树库（PropBank）同时使用了原型角色（proto-roles）和动词特定的（verb-specific）语义角色。</p>
</li>
<li><p>框架网络（FrameNet）使用框架特定的（frame-specific）语义角色。</p>
</li>
</ol>
<h4 id="命题树库（The-Proposition-Bank，PropBank）"><a href="#命题树库（The-Proposition-Bank，PropBank）" class="headerlink" title="命题树库（The Proposition Bank，PropBank）"></a>命题树库（The Proposition Bank，PropBank）</h4><p>PropBank：标注了语义角色的句子的资源库。标记的是宾州树库（Penn<br>Treebank）中的句子。</p>
<p>PropBank 中语义角色特定于动词；FrameNet 中的语义角色特定于框架。</p>
<h4 id="框架网络（FrameNet）"><a href="#框架网络（FrameNet）" class="headerlink" title="框架网络（FrameNet）"></a>框架网络（FrameNet）</h4><p>框架是一个类似于脚本的结构，实例化一组称之为框架元素（frame<br>elements）的特定于框架的语义角色。每个词唤起一个框架，并且描述及其元素的一些方面。</p>
<p>框架中的语义角色（即框架元素）包括：核心角色（core roles）和非核心角色（non-core<br>roles）。</p>
<p>FrameNet 还编码了框架和框架元素间的关系。框架间可以彼此继承，不同框架的元素间的泛化关系也可以通过继承获得。框架间的其他关系，例如：因果关系，也同样被表示。</p>
<h4 id="选择限制（selectional-restrictions）"><a href="#选择限制（selectional-restrictions）" class="headerlink" title="选择限制（selectional restrictions）"></a>选择限制（selectional restrictions）</h4><p>语义角色通过论元与谓词之间的关系来表示论元的语义。</p>
<p>选择限制是一种语义类型限制，表示一个动词对允许填充到它的论元角色的概念类别的限制。</p>
<p>使用事件表示来捕获选择限制的语义。</p>
<p>表示语义角色的选择限制的方法是使用 WordNet 的同义集而非逻辑概念。每个谓词指定 WordNet 的一个同义集作为每个论元的选择限制。如果填充语义角色的词是同义集的上位词，那么这个意义表示就是良构的。</p>
<h3 id="基元分解"><a href="#基元分解" class="headerlink" title="基元分解"></a>基元分解</h3><p>基元分解（primitive decomposition）或者成分分析（componential<br>analysis）的模型在词义定义中的应用。基元分解可以状态和行为之间或使动与非使动谓词之间的相似性，但是需要依赖于先拥有的大量的谓词。由于难以提出表示所有可能意义的基元集合，所以语义基元在现有的计算机语言学工作中应用不多。</p>
<p>语义特征（semantic features）：表示某种基元意义的符号。</p>
<p>概念依存（Conceptual Dependency，CD）是动词性谓词分解方法。</p>
<h3 id="隐喻（metaphor）"><a href="#隐喻（metaphor）" class="headerlink" title="隐喻（metaphor）"></a>隐喻（metaphor）</h3><p>隐喻：与借喻（metonymy）类似，即用意义来自完全不同领域的词或短语来提及或探讨另一个领域及其概念。</p>
<h3 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h3><ul>
<li><p>词汇语义学（lexical</p>
<ol>
<li>semantics）研究词的意义以及词之间系统化的意义关联的关系。</li>
</ol>
</li>
<li><p>词义（word</p>
<ol>
<li>sense）是词的意义的体现，定义以及关系通常在词义的层面定义，而不在词形层面定义。</li>
</ol>
</li>
<li><p>同形关系（homonymy）是指两个含义共享一个词形但是意义之间没有关联。</p>
</li>
<li><p>多义关系（polysemy）是指两个含义共享一个词形并且意义之间有关联。</p>
</li>
<li><p>同义关系（synonymy）是指具有相同意义的不同词间的关系。</p>
</li>
<li><p>上下位关系（hyponymy）是指具有类别包含（class-inclusion）关系的词间的关系。</p>
</li>
<li><p>语义场（semantic field）被用于捕捉某个单独领域的某个词位集之间的语义关系。</p>
</li>
<li><p>WordNet：是一个大规模的英语词汇信息库。</p>
</li>
<li><p>语义角色（semantic</p>
<ol>
<li>roles）从特定深层语义角色出发，通过归纳各类动词之间的相似角色抽象得出。</li>
</ol>
</li>
<li><p>题旨角色（thematic roles）是基于一个有限角色列表的语义角色模型。</p>
<ul>
<li><p>PropBank：实现了动词特定的语义角色及原型施事（proto-agent）∕原型受事（proto-patient）</p>
</li>
<li><p>FrameNet：实现了框架特定的角色列表</p>
</li>
</ul>
</li>
<li><p>语义选择限制（selectional</p>
<ol>
<li>restriction）：容许词（特别是谓词）对论元词设置某些语义限制。</li>
</ol>
</li>
<li><p>基元分解（primitive</p>
<ol>
<li>decomposition）是词意义表示的一种方法，基于词元词汇的有限集合。</li>
</ol>
</li>
</ul>
<h2 id="计算词汇语义学"><a href="#计算词汇语义学" class="headerlink" title="计算词汇语义学"></a>计算词汇语义学</h2><p>语境的相似性可以用于计算语义的相似性。</p>
<p>计算词汇语义学（computational lexical semantics）：词义计算。</p>
<ol>
<li><p>词义排歧（word sense</p>
<ol>
<li>disambiguation，WSD）：检查语境中的词例，并决定每个单词在该语境下的义项。</li>
</ol>
</li>
<li><p>词语相似性（word</p>
<ol>
<li>similarity）计算以及词语之间的关系（上位词、下位词、部分词）。依靠语料相似性以及依靠类似 WordNet 的结构化资源。</li>
</ol>
</li>
<li><p>语义角色标注（semantic role labeling），也叫格角色指派（case role</p>
<ol>
<li>assignment）或者题旨角色指派（thematic roles</li>
<li>assignment）。从句法分析中得到的特征去指派语义角色。</li>
</ol>
</li>
</ol>
<h3 id="词义排歧（WSD）：综述"><a href="#词义排歧（WSD）：综述" class="headerlink" title="词义排歧（WSD）：综述"></a>词义排歧（WSD）：综述</h3><p>两种不同的 WSD 任务：</p>
<p>词汇采样（lexical<br>sample）：一小组预先定好的词语被选择出来，同时每一个词语在特定词典中的目标语义集合也被选择出来。因为词的集合和词义的集合都很小，可以使用监督机器学习算法来处理。先手工标注选出的词语，然后训练分类系统，接着就可以标注没有手工处理的词语。</p>
<p>全词排歧（all-word<br>disambiguation）：系统输入为整个文本，以及对每个单词都标注了对应词义目录的词典，系统对文本中每一个词都需要排歧。问题是标记集很大，因为数据稀疏问题无法构建大量可用的训练数据，。</p>
<h3 id="有监督词义排歧"><a href="#有监督词义排歧" class="headerlink" title="有监督词义排歧"></a>有监督词义排歧</h3><p>使用监督学习方法解决词义排歧的问题：从文本中抽取对于预测特定词义有帮助的特征，然后利用这些特征训练一个分类器用来给词语指定一个正确的词义，训练的结果是使用分类器给文本中未标注词语指定词义标签。</p>
<p>对于词汇采样任务，面向单个词语的标注语料库。语料包含目标词语的上下文句子及该目标词语的正确语义标注。</p>
<p>对于全词排歧任务，使用 semantic<br>concordance 语料，语料中每一个句子中的开放性词语都标注有来自特定字典或者同义词词典的正确语义。</p>
<h4 id="监督学习的特征抽取"><a href="#监督学习的特征抽取" class="headerlink" title="监督学习的特征抽取"></a>监督学习的特征抽取</h4><p>监督训练需要抽取对词义具有预测性质的特征。特征向量（feature<br>vector）由数值构成，编码了语言学信息，是机器学习算法的输入。从邻近的上下文中可以抽取两类特征：搭配特征和词袋特征。词义排歧方法同时使用了搭配特征和词袋特征。</p>
<p>搭配特征（collocational<br>feature）是指与目标词语有特定位置关系的词语或短语，包含了目标词语左右特定位置的信息。从这些上下文词语中抽取的典型特征包括：单词本身、单词的原形以及该单词的词性。这些特征能够有效地包含局部词汇和语法信息，而这些信息通常能准确地区分给定的词义。</p>
<p>词袋特征（bag-of-words<br>feature）包含了邻近词语的词袋的信息。词袋是词语的无序集合，忽略了词语的位置信息。采用将目标词语的上下文表示为特征向量。词汇集从训练集中预先选择词语的有用子集。目标词语附近的上下文区域是以目标词语为中心的对称的固定大小的窗口。词袋特征能够有效地捕捉目标词语所在的上下文的一般主题信息，很容易地确定属于特定领域词语的意思。</p>
<h4 id="朴素贝叶斯分类器-和-决策表分类器"><a href="#朴素贝叶斯分类器-和-决策表分类器" class="headerlink" title="朴素贝叶斯分类器 和 决策表分类器"></a>朴素贝叶斯分类器 和 决策表分类器</h4><p>相互贝叶斯分类器是基于特征独立假设（朴素地（naively）假设各特征之间相互独立），即给定词义特征之间是条件独立的。使用朴素贝叶斯分类器进行词义排歧时通常利用拉普拉斯平滑方法将概率平滑。</p>
<p>决策表分类器（decision list classifiers）：产生了一系列选择条件。</p>
<h3 id="WSD-评价：方法、基准线、上限"><a href="#WSD-评价：方法、基准线、上限" class="headerlink" title="WSD 评价：方法、基准线、上限"></a>WSD 评价：方法、基准线、上限</h3><p>评价 WSD 这样的组件技术是很复杂的，目标是对 WSD 在端到端应用中的效果评价。</p>
<p>评价嵌入到端到端应用的组件 NLP 任务称为外在评价（extrinsic<br>evaluation）、基于任务（task-based）的评价、端到端（end-to-end）的评价或体内（in<br>vivo）评价。</p>
<p>由于外在评价非常困难，并且对应用来说非常耗时，不易推广，因此 WSD 系统通过采用内在评价。内在（intrinsic）评价或体外（in<br>vitro）评价。将 WSD 组件看成一个独立于任何给定应用的单独系统。系统通过其精确匹配词义准确率（sense<br>accuracy）来评价，即在测试集中系统标注与人工标注一致的词义所占的百分比。</p>
<p>SENSEVAL 已经对语义评价进行了标准化。提供了共享任务以及该任务的训练和测试语料，并建立了多种语言下的词汇采样和全词排歧任务的语义清单（sense<br>inventories）。</p>
<p>基准线（baseline）标准、上限（ceiling）标准。</p>
<h3 id="WSD：字典方法和同义词库方法"><a href="#WSD：字典方法和同义词库方法" class="headerlink" title="WSD：字典方法和同义词库方法"></a>WSD：字典方法和同义词库方法</h3><p>使用字典或同义词库的非直接监督方法</p>
<h4 id="Lesk-算法"><a href="#Lesk-算法" class="headerlink" title="Lesk 算法"></a>Lesk 算法</h4><p>简化的 Lesk 算法：计算词义的字典注释或定义和目标词语邻近词语的次，然后把次最大的词义赋给目标词语。</p>
<p>Corpus<br>Lesk 算法：不仅仅计算重叠词语的个数，还为每个重叠词语赋予一个权重。权重是逆文档频率（inverse<br>document frequency，IDF）。</p>
<p>Lesk 算法与监督方法的结合可以通过添加类似 Lesk 词袋特征的方式实现。</p>
<h4 id="选择限制和选择优先度"><a href="#选择限制和选择优先度" class="headerlink" title="选择限制和选择优先度"></a>选择限制和选择优先度</h4><p>选择限制（Ref：Ch19）可以作为词义排歧的知识资源。谓词通过排除那些违背其某一选择限制的词义来判断歧义词语的正确意思。由于硬性限制导致合法的句子与选择限制的冲突，因此选择限制常常作为参考条件而不是必要条件。</p>
<p>在词义排歧方面，选择优先性的 Resnik 模型和其他无监督方法一样好，但是不如 Lesk 或有监督方法。</p>
<p>选择优先度（selectional preference<br>strength）：谓词提供了关于其变量语义类别的大体信息量。可以定义为两个分布之间的信息差异：期望语义类别 P(c) 的分布（直接宾语落入到类别 c 的可能性）和给定特定怕期望语义类别 P(c|v) 的分布（动词 v 的直接宾主落入到类别 c 的可能性）。这两个分布的差异越大，动词提供关于其宾语的信息就越多。两个分布之间的差异可以用相对熵（relative<br>entropy）或者 Kullback-Leiber 散度距离来衡量。</p>
<p>特定类和动词的选择关联性（selectional<br>association）作为该类别对动词一般选择优先度的相对贡献，是一个概率度量，用来度量谓词和支配谓词变元的类别的关联程序。</p>
<h3 id="半监督-WSD（最小化监督的-WSD）：自举法"><a href="#半监督-WSD（最小化监督的-WSD）：自举法" class="headerlink" title="半监督 WSD（最小化监督的 WSD）：自举法"></a>半监督 WSD（最小化监督的 WSD）：自举法</h3><p>WSD 的有监督方法和基于字典的方法都需要大量的手工构建的资源，有监督方法需要监督训练集，基于字典的方法需要大规模的词典。</p>
<p>自举（bootstrapping）算法，也被称为半监督学习（semi-supervised<br>learning）或最低限度的监督学习（minimally supervised<br>learning），只需要非常小的人工标注训练集。</p>
<p>Yarowsky 算法的目标是为特定目标词语建立一个分类器（在词汇采样任务中）。具备是由小的种子集合构造较大训练集的能力。需要一个准确的初始种子集合以及一个好的置信度衡量，从而能够选出好的新例子添加到训练集中。产生初始种子的方法是手工标注一部分实例和启发式地选择正确的种子。</p>
<p>一个搭配一个词义（one sense per<br>collocation）假设：和目标词义有很强联系的特定词语或短语不可能与其他词义共现。</p>
<p>一段话语一个词义（one sense per<br>discourse）假设：一个特定词语在一段正文或一篇文章中多次出现，那么通常具有相同的意思。这个假设的有效性依赖于语义的粒度，大部分情况下语义粒度越粗越有效。</p>
<h3 id="词语相似度：语义字典方法"><a href="#词语相似度：语义字典方法" class="headerlink" title="词语相似度：语义字典方法"></a>词语相似度：语义字典方法</h3><p>词语相似度（word similarity）或语义距离（semantic<br>distance）度量来代替同义关系。两个词拥有的相同意思特征越多或两个词是近义词，则两个词的相似度就越高或语义距离越近。</p>
<p>度量词语相似度的两种算法：</p>
<ul>
<li><p>基于语义字典（thesaurus-based）算法：使用类似 WordNet 或 MeSH 的在线语义字典来度量两个义项之间的距离。通常使用上位关系（继承关系）∕下位关系（包含关系）的层次结构。</p>
<ul>
<li>WordNet 算法只能计算名词和名词之间的或动词或动词之间的相似度，而不能计算名词与动词、形容词或其他词性之间的相似度。</li>
</ul>
</li>
<li><p>基于分布（distributional）算法（Ref：Sec20.7）</p>
</li>
</ul>
<p>词语相似度（word similarity）和词语相关度（word relatedness）的差别：</p>
<ul>
<li><p>词语相似度是指两个词是近义词或在上下文中可以近似替代。</p>
</li>
<li><p>词语相关度是指一大类词语之间的潜在关系。</p>
</li>
</ul>
<p>词语相似度是词语相关度的子情况。因此本节中算法统称为相似度度量。</p>
<ul>
<li><p>在语义字典层次结构图中两个词语或义项之间的路径越短就越相似。基本的路径长度算法的隐含假设是网络中每个链接代表的距离相同。</p>
</li>
<li><p>信息量词语相似度（information-content</p>
<ol>
<li>word-similarity）算法仍然依赖于语义字典的结构，但是添加了从语料库中提取出来的概率信息，属于细粒度的衡量。</li>
</ol>
<ul>
<li><p>遵循基本的信息理论</p>
</li>
<li><p>两个概念的最低公共包含结点（lowest common</p>
<ol>
<li>.  subsume，LCS）。Resnik 提出利用两个结点的最低公共包含结点的信息量去估计它们共同的信息量</li>
</ol>
</li>
</ul>
</li>
<li><p>基于字典的方法（注释是字典的属性而不是语义字典的属性）：如果字典中两个概念或者义项的注释包含相同的词语，则它们就相似。</p>
</li>
</ul>
<p>基于语义字典的相似度评价（Evaluating Thesaurus-Based Similarity）</p>
<ul>
<li><p>内在评价方法是计算算法得出的词语相似度分数和人工标注的词语相似度排序的相关序数；</p>
</li>
<li><p>外在评价方法是把相似度度量方法嵌入到某些终端应用中。</p>
</li>
</ul>
<h3 id="词语相似度：分布方法"><a href="#词语相似度：分布方法" class="headerlink" title="词语相似度：分布方法"></a>词语相似度：分布方法</h3><p>分布（distributional）方法直接为 NLP 任务提供词语相关性度量，还可以用来自动生成语义字典（automatic<br>thesaurus<br>generation），以及自动地给在线语义字典添加新同义关系和其他关系（如：下位关系、部件关系等）。</p>
<p>一个词语的意思与它周围词语的分布相关（由词之伴可知其意！）</p>
<p>分布相似度度量方法需要确定三个参数：</p>
<ul>
<li><p>共现的词语；（Ref：Sec20.7.1）</p>
</li>
<li><p>词语赋予权重；（Ref：Sec20.7.2）</p>
</li>
<li><p>向量距离度量方法。（Ref：Sec20.7.3）</p>
</li>
</ul>
<h4 id="定义词语的共现向量"><a href="#定义词语的共现向量" class="headerlink" title="定义词语的共现向量"></a>定义词语的共现向量</h4><p>使用和目标词语具有某种语法关系（grammatical relation）或依存关系（dependency<br>relation）的词语。</p>
<p>实体的意义以及实体间语法关系的意义，和这些实体相对于其他实体的结合限制相关。</p>
<h4 id="度量与上下文的联系"><a href="#度量与上下文的联系" class="headerlink" title="度量与上下文的联系"></a>度量与上下文的联系</h4><p>目标词语和给定特征之间的权重（weights）或关联度（association）。</p>
<p>点间互信息（Pointwise Mutual<br>Information，PMI）用来度量两个事件的共现频数与假设二者互相独立时它们共现出现的期望频数的比值。</p>
<h4 id="定义两个向量之间的相似度（向量计算）"><a href="#定义两个向量之间的相似度（向量计算）" class="headerlink" title="定义两个向量之间的相似度（向量计算）"></a>定义两个向量之间的相似度（向量计算）</h4><p>两个向量之间的距离的度量方法：</p>
<ul>
<li><p>曼哈顿距离（Manhattan distance），也被称为 Levenshtein 距离，或者 L1 范数。</p>
</li>
<li><p>欧几里德距离（Euclidean distance），也被称为 L2 范数。</p>
</li>
</ul>
<p>相似度计算：点乘（dot product）或者内积（inner product）。</p>
<p>向量长度归一化。</p>
<p>Jaccard 度量方法，也称为 Tanimoto 度量方法，或者最小∕最大度量方法。</p>
<p>分布相似度度量方法：KL 散度距离或相对熵。</p>
<p>Jenson-Shannon 散度距离。</p>
<h4 id="评价分布式词语相似度"><a href="#评价分布式词语相似度" class="headerlink" title="评价分布式词语相似度"></a>评价分布式词语相似度</h4><p>分布式算法使用内在方式评价：与一个标准的语义字典进行比较。使用 t 检验对关联度进行加权，使用 Dice 或 Jaccard 算法去度量向量相似度。</p>
<h3 id="词语关系：下位关系及其他关系"><a href="#词语关系：下位关系及其他关系" class="headerlink" title="词语关系：下位关系及其他关系"></a>词语关系：下位关系及其他关系</h3><p>词语语义关系：相似关系、下位关系、上位关系、反义关系、部件关系。</p>
<p>自动学习语义关系利用词汇——句法模式（lexico-syntactic<br>pattern）。用来推断下位关系的五种模式：图 20.14（P547）</p>
<p>在关系模式挖掘中发现新模式的方法有：</p>
<p>自举法：在大规模语料中具备某种关系的词语能够同时出现在这种关系的多种不同模式中。因此，仅仅需要从一小部分准确的模式去获取具备给定关系的词语集合。然后，这些词语可以用来在大规模语料中查询以某种依赖关系包含这些词语的句子；新的模式可以从这些新的句子中抽取出来。这个过程可以一直重复直到模式集合足够大。使用自举法时需要避免语义漂移。（Ref：Ch22）</p>
<p>大规模的词汇资源（如 WordNet）作为训练信息的来源，每一对上位∕下位关系提供关系中词语的某些信息，然后训练分类器用来寻找具备这种关系的词语。</p>
<p>选择未知词语在一个完整层次结构中的插入位置。</p>
<p>类似命名实体识别的标注任务。使用 WordNet 中的广义分类标签，抽取特征，使感知器分类器。</p>
<p>寻找部分关系（meronyms）很困难，因为表示该关系的词汇——句法模式极具歧义。</p>
<p>学习词语之间的关系是字典归纳（thesaurus<br>induction）任务的重要组成部分。在字典归纳中，词语间的相似度估计、上下位关系和其他关系被整合起来构造成一个完全的知识本体或者字典。</p>
<p>两阶段字典归纳算法：</p>
<p>自底向上的聚类（clustering）算法，将语义上类似的词语聚集到不带标签的词语层次结构中；</p>
<p>给定不带标签的层次结构，使用基于模式的下位关系分类器去为每一类中的词语指定上位关系标签。</p>
<h3 id="语义角色标注"><a href="#语义角色标注" class="headerlink" title="语义角色标注"></a>语义角色标注</h3><p>语义角色标注（semantic role labeling），也称为主题角色标注（thematic role<br>labeling）或者格角色赋值（case role assignment）或者浅层语义分析（shallow<br>semantic<br>parsing）：将词语的意义与句子的语义进行链接。目的是自动发现句子中谓语的语义角色。即找出句子中给定谓语的语义变元，为每个变元选择合适的角色。能够改善所有语言理解应用的质量。</p>
<p>主要的语义角色标注方法：基于有监督机器学习，需要大量的训练和测试资源，主要利用 FrameNet 和 PropBank 资源。</p>
<p>语义角色标注都从句法分析开始，通过遍历句法分析的结果来寻找所有的谓语承接语。遍历句法分析树来确定成分与谓语角色的对应，从而将句法成分描述成谓语对应的特征集合，然后利用训练得到的分类器来基于这些特征做出判断。常用特征有：</p>
<ul>
<li><p>管辖谓语</p>
</li>
<li><p>句法成分的短语类型</p>
</li>
<li><p>句法成分的中心词</p>
</li>
<li><p>句法成分的中心词词性</p>
</li>
<li><p>在句法分析树中从成分到谓词之间的路径</p>
</li>
<li><p>成分所在人名的时态</p>
</li>
<li><p>句法成分和谓词之间的二元线性位置，其值或是前面或是后面</p>
</li>
<li><p>谓语的次范畴化</p>
</li>
</ul>
<p>特征按照上面提到的顺序进行排列。</p>
<p>多阶段分类器：剪枝、识别、分类。</p>
<p>语义角色标注需要注意成分重叠问题，因为成分的语义角色是相互依赖的，因此可以采用 N-best 重打分技术。先利用分类器为每个成分指定多个标签，每个标签都有一定的概率，然后再使用全局最优的算法从中挑选最好的标签序列。</p>
<p>利用组块技术可以直接对原始（或者带有词性标注）文本进行语义角色标注。</p>
<p>在评价语义角色标注系统时要求把每个变元正确地指派到相应的词语序列或句法分析成分上。因此可以计算准确率、召回率和 F 值。</p>
<p>一个简单的基于规则的系统可以用来作为基准系统。</p>
<h3 id="无监督语义排歧"><a href="#无监督语义排歧" class="headerlink" title="无监督语义排歧"></a>无监督语义排歧</h3><p>在语言应用中使用较多的是凝聚式聚类（agglomerative clustering）算法。</p>
<p>评价无监督的词义排歧方法，最好做外在或体内测试。</p>
<h3 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h3><p>词义排歧（Word-Sense<br>Disambiguation，WSD）判定特定上下文中词语的正确义项。监督方法利用单个词语（单词任务）或所有词语（全词任务）出现的句子，这些句子使用 WordNet 中的义项进行了标注。监督 WSD 使用朴素贝叶斯分类器、决策列表分类器以及其他分类器进行训练和预测，分类器是在描述词语上下文的词中的搭配特征和词袋特征上进行训练。</p>
<p>WSD 的重要基准系统是选用最频繁词义，等价于 WordNet 中取词语的第一个意义。</p>
<p>Lesk 算法选择字典定义中和目标词语的上下文重叠词语最多的义项作为目标词语的词义。</p>
<p>词语相似度可以通过度量语义字典中的链接距离或者语义字典中的信息含量，使用语料中的分布相似度或者通过使用信息论方法来计算。</p>
<p>分布式相似度的关联度度量方法包括：PMI、Lin 和 t-test。向量相似度的度量方法包括：余弦、Jaccard、Dice 和 Jiang-Conrath。</p>
<p>词汇间的关系（如：下位关系）可以通过词汇——句法模式发现并识别。</p>
<p>语义角色标注通常从对句子进行句法分析开始，然后自动地为句法分析树中的每个结点标识语义角色。</p>
<h2 id="计算话语学"><a href="#计算话语学" class="headerlink" title="计算话语学"></a>计算话语学</h2><p>话语（discourse）：由搭配在一起、具有一定结构并且连贯（coherent）的句子群组成的。</p>
<p>话语的类型：</p>
<ul>
<li><p>独白（monologue）</p>
</li>
<li><p>对话（dialogue）</p>
<ul>
<li><p>人和人的对话（human-human dialogue）</p>
</li>
<li><p>人机对话（human-computer dialogue）</p>
</li>
</ul>
</li>
</ul>
<p>指代消解（Reference Resolution）：决定代词以及其他名词短语指代的内容。</p>
<ul>
<li><p>代词回指消解（anaphora resolution）</p>
</li>
<li><p>共指消解（coreference resolution）</p>
</li>
</ul>
<p>连贯关系（coherence<br>relations）：决定话语中句子间的连贯结构。连贯话语中的句子之间必须有语义上的联系。</p>
<p>基于实体的一致性（entity-based<br>coherence）是一种连贯性，说明连贯的话语与涉及在话语中实体之间必须表现出一定的关系。</p>
<p>话语结构：简单话语分割（discourse segmentation）和连贯性关系（coherence<br>relation）。</p>
<p>简单话语分割：就是把一篇文档分割成线性序列的多个段落的篇章。</p>
<p>篇章→关系→实体。</p>
<h3 id="话语分割"><a href="#话语分割" class="headerlink" title="话语分割"></a>话语分割</h3><p>话语分割（discourse segmentation）：把一篇文档切分成一个线性的子主题序列。</p>
<p>使用内聚机制寻找话语结构。</p>
<h4 id="无监督话语分割"><a href="#无监督话语分割" class="headerlink" title="无监督话语分割"></a>无监督话语分割</h4><p>线性分割（linear<br>segmentation）：把文本分割成多个多段单元的任务，其中每个单元表示原谅中的一个子主题或者段落。</p>
<p>内聚性（cohesioin）：是指用一定的语言学手段将文本单元联系或者连接在一起。</p>
<p>词汇内聚性（lexical<br>cohesion）：是指两个语言单元中基于词语音关系列表现出来的内聚性。</p>
<p>非词汇内聚性：例如，使用回指（anaphora），也称指代或者首语重复。</p>
<p>内聚链：通过相关词语的一个序列表现出来的内聚性。</p>
<p>内聚性（cohesion）与连贯性（coherence）的区别。</p>
<ul>
<li><p>内聚性：指的是文本单元联系在一起的方式，把两个单元聚成一个单元。</p>
</li>
<li><p>连贯性：用来解释不同文本单元的意义如何结合在一起以表达一个更大粒度的话语意义，是两个单元意义之间的关系。</p>
</li>
</ul>
<p>线性话语分割的无监督算法基于内聚性。基于内聚性的分割算法的都是同一个子主题中的句子或者段落之间具有内聚性，而相邻的子主题之间的段落则没有这种内聚性。因此，度量内聚性时希望子主题内部的内聚性强，邻近子主题的内聚性弱。</p>
<p>基于内聚性的算法：TextTilling 有三个部分</p>
<ul>
<li><p>分词（tokenization）</p>
</li>
<li><p>词汇分值确定（lexical score determination）</p>
<ul>
<li>词汇内聚性得分（lexical cohesion score）</li>
</ul>
</li>
<li><p>边界识别（boundary identification）</p>
<ul>
<li>深度分数（depth score）</li>
</ul>
</li>
</ul>
<h4 id="有监督话语分割"><a href="#有监督话语分割" class="headerlink" title="有监督话语分割"></a>有监督话语分割</h4><p>基于多种分类器完成有监督话语分割。</p>
<p>特征：无监督分类特征的超集（内聚性特征、词语重叠度、词语的余弦距离、LSA、词汇链、共指等等）</p>
<p>话语标记（discourse markers）或提示词（cue word）：表现话语结构的词语或者短语。</p>
<p>话语标记是领域特定的，可以利用手写规则或者正则表达式去确定特定领域的话语标志。在话语分割的预处理阶段需要进行命名实体识别，</p>
<h4 id="话语分割的评价"><a href="#话语分割的评价" class="headerlink" title="话语分割的评价"></a>话语分割的评价</h4><p>WindowDiff 通过在系统输出的分割上滑动一个探测器，即大小为 k 的滑动窗口，来对自动标注的边界和人工标注的边界进行比较。</p>
<p>因为准确率、召回率以及 F 值对分割边界的距离误差不敏感，因此不使用它们来评价分割算法。</p>
<h3 id="文本连贯性"><a href="#文本连贯性" class="headerlink" title="文本连贯性"></a>文本连贯性</h3><p>连贯关系（coherence relations）：话语的话段之间所有可能的连接</p>
<p>结果（Result）：推测 A 声明的状态或者事件导致了 B 声明的状态或者事件。</p>
<p>说明（Explanation）：推测 B 声明的状态或者事件导致了 A 声明的状态或者事件。</p>
<p>平行（Parallel）：推测 A 声明的和推测 B 声明的都是类似的。</p>
<p>细化（Elaboration）：推测 A 声明和推测 B 声明的是同一个命题。</p>
<p>时机（Occasion）：推测从 A 声明的状态到 B 声明的最终状态的状态变化，或者推测从 B 声明的状态到 A 声明的最初状态的状态变化。</p>
<p>树中每个结点代表一组局部连贯的从句或者句子，称之为话语片断（discourse<br>segment）。</p>
<h4 id="修辞结构理论"><a href="#修辞结构理论" class="headerlink" title="修辞结构理论"></a>修辞结构理论</h4><p>修辞结构理论（Rhetorical Structure<br>Theory，RST）：是连贯关系理论中的一种，是一种文本组织模型，应用在文本生成领域。包含了 23 种修辞关系，用于表示话语中不同跨度的文本之间的关系。大部分修辞关系保持在两个文本跨度之间，一个作为核心（nucleus），一个作为外围（satellite）。核心是更接近作者意图的并且能够独立解释的单元，外围是离作者意图远些并且通常需要和对应的核心一起解释。</p>
<p>在证据关系（Evidence），外围为核心表述的观点或情况提供证据。</p>
<p>RST 关系：</p>
<ul>
<li><p>细化（Elaboration）：外围对核心做进一步的补充说明</p>
</li>
<li><p>属性（Attribution）：外围给出核心中转述语实例的属性来源</p>
</li>
<li><p>对照（Contrast）：多核心关系，两个或多个核心在某些重要的维度上进行对比</p>
</li>
<li><p>并列（List）：多核心关系，两个或多个核心不进行比较</p>
</li>
<li><p>背景（Background）：外围给出解释核心的上下文</p>
</li>
</ul>
<h4 id="自动连贯指派"><a href="#自动连贯指派" class="headerlink" title="自动连贯指派"></a>自动连贯指派</h4><p>连贯关系指派（coherence relation<br>assignment）：给定一个句子串，自动确定句子之间的连贯关系。</p>
<p>话语分析（discourse parsing）：抽取能够表示整个话语的树或图。</p>
<p>基于提示短语（cue phrases）的浅层算法。</p>
<ol>
<li>识别文本中的提示短语。</li>
</ol>
<ul>
<li><p>提示短语（cue phrase），或者话语标志（discourse marker），或者提示词（cue</p>
<ol>
<li>word）是能够指示话语结构的词或者短语，特别是能够把话语片段联系在一起。</li>
</ol>
</li>
<li><p>连接语（connectives）是一种提示短语，通常是连词或者副词，提供了两个片段之间存在的连贯关系的线索。</p>
</li>
</ul>
<ol>
<li>基于提示短语把文本分割成话语片断。</li>
</ol>
<ul>
<li><p>话语片断的大小是从句或者类似从句的单元。</p>
</li>
<li><p>基于单个提示短语手工编写分割规则。</p>
</li>
<li><p>利用句法分析器，可以利用句法短语制定更加复杂的分割规则。</p>
</li>
</ul>
<ol>
<li>利用提示短语对连续话语片段间的关系进行分类。</li>
</ol>
<ul>
<li><p>为话语标志撰写规则，但是注意提示短语的歧义性带来的问题</p>
</li>
<li><p>使用自举法对大规模语料进行连贯关系自动标注，从而满足训练分类器需要的大量数据。</p>
</li>
<li><p>使用正则表达式抽取包围提示短语的话语片段对，然后移除提示短语。最终的句子对不带有提示短语，就可以用于抽取连贯关系的监督训练集。</p>
</li>
</ul>
<p>基于溯因推理（abduction）的算法。</p>
<h3 id="指代消解"><a href="#指代消解" class="headerlink" title="指代消解"></a>指代消解</h3><p>指代消解（reference resolution）：决定哪些实体被哪些语言表述所指代。</p>
<p>提示语（referring expression）：用于实现指代的自然语言表达。</p>
<p>所指对象（referent）：指向的实体。</p>
<p>共指（corefer）：两个指示语用于指向同样的实体。</p>
<p>先行词（antecedent）：以一种方式准许使用另一个提示语。</p>
<p>复指（anaphora）或者回指：提及一个先前已经被引入话语的实体。使用的指示语是复指语（anaphoric）。</p>
<p>指向实体的方式依赖于实施的话语上下文（discourse<br>context），还依赖于话语的情境上下文（situational context）。</p>
<p>话语模型（discourse<br>model）：具有特定地位的信念子集形成了听话人对正在进行的话语的心理模型，包括本话语中所指向实体的表示以及它们参与的关系。</p>
<p>指代消解系统的两个部分：</p>
<ul>
<li><p>构造话语模型的方法，该模型能够随着所表示的话语的动态变化而演化；</p>
</li>
<li><p>各种指示语暗含的信息到听话人的信念集之间的映射方法，包括该话语模型。</p>
</li>
</ul>
<p>话语模型的两个基本操作：</p>
<ul>
<li><p>当话语中首次提及所指对象时，表示对象被唤起（evoke）而进入模型；</p>
</li>
<li><p>当话语中再次提及所指对象时，从模型中访问（access）它的表示。</p>
</li>
</ul>
<p>指代消解的两种任务：</p>
<ul>
<li><p>代词回指消解（pronominal anaphora</p>
<ol>
<li>resolution）：找出一个代词的先行词，也可以将人称代词消解看成共指消解的子任务。</li>
</ol>
</li>
<li><p>共指消解（coreference</p>
<ol>
<li>resolution）：找出文中所有的指向同一实体的指示词，即找出所有具有共指（corefer）关系的表述。一系列的指示语称为共指链（coreference</li>
<li>chain）。</li>
</ol>
</li>
</ul>
<h3 id="指代现象"><a href="#指代现象" class="headerlink" title="指代现象"></a>指代现象</h3><h4 id="指示语的五种类型"><a href="#指示语的五种类型" class="headerlink" title="指示语的五种类型"></a>指示语的五种类型</h4><ol>
<li><p>不定名词短语（indefinite noun</p>
<ol>
<li>phrase）：不定所指将一个新的实体引入了话语环境。</li>
</ol>
</li>
<li><p>有定名词短语（definite noun phrase）：指示对象可以确认的实体。</p>
</li>
</ol>
<p>. 1. 实体在文本中已经被提起，并且也被表示于话语模型中</p>
<p>. 2. 实体包含在听话人关于世界的信念集中</p>
<p>. 3. 实体本身的描述就包含了唯一性。</p>
<ol>
<li>代词（Pronoun）：使用代词的所指相比有定名词短语受到更强的约束，要求在话语模型中所指对象具有高度的活力或者显著性。代词指示的实体被引入的位置相比有定名词短语的要近。</li>
</ol>
<p>. 1. 代词也可以参与提前指代（cataphora），即在代词所指对象出现之前就提及代词。</p>
<ol>
<li>指示代词（Demonstrative）：即可以单独出现，也可以作为限定词。</li>
</ol>
<p>. 1. “this”是近端指示词（proximal<br>. .  demonstrative）：表示文字上或者隐喻上比较接近；</p>
<p>. 2. “that”是远端指示词（distal<br>. .  demonstrative）：表示文字上或者隐喻上相隔较远（例如：时间上相隔较远）</p>
<ol>
<li>名字（Names）：包括人名、机构名和地名。在话语中名字可以用来指代新的或者旧的实体。</li>
</ol>
<h4 id="信息状态"><a href="#信息状态" class="headerlink" title="信息状态"></a>信息状态</h4><p>相同的指示语（如许多不定名词短语）能够用来表示新的指示对象，其他的指示语（如许多确定名词短语）可以用来指向旧的所指对象。</p>
<p>信息状态（information status）或信息结构（information<br>structure）：对不同所指形式提供新的或者旧的信息的方式。</p>
<p>话语中不同各类的所指形式和所指对象的信息度或者显著性之间的关系：</p>
<ul>
<li><p>约定层级（givenness</p>
<ol>
<li>hierarchy）：表示 6 种信息状态的尺度，每一种信息状态由不同的指示语指示。</li>
</ol>
</li>
<li><p>相关接受度尺度（accessibility scale）：</p>
<ul>
<li><p>越显著的所指对象越容易唤醒听者的回忆，因此可用较少语言材料的内容来指代；</p>
</li>
<li><p>不显著的实体需要较长的和较显著的指示语来帮助听者恢复所指对象。</p>
</li>
</ul>
</li>
<li><p>听者状态和话语状态来分析信息状态。</p>
<ul>
<li><p>听者状态表明所指对象对听者来说是已经知道的或者是新的；</p>
</li>
<li><p>话语状态表明所指对象在话语的前面部分是否已经被提起。</p>
</li>
</ul>
</li>
</ul>
<p>指示语形式和信息状态之间的关系：</p>
<ul>
<li><p>推理对象（inferrables）：也叫桥接推理（bridging</p>
<ol>
<li>inferences），或者中间物（mediated）。“指示语”不指向文中已经被明显唤起的实体，而是指向与唤起实体具有推理性关系的实体。</li>
</ol>
</li>
<li><p>类属指代（generics）：“指示语”不指向文中已经被明显唤起的实体，而是指向与唤起实体具有同类关系的实体。</p>
</li>
<li><p>无所指形式（non-referential forms）：某些无所指形式与指示语在表面上很相似。</p>
</li>
</ul>
<h3 id="代词回指消解所使用的特征"><a href="#代词回指消解所使用的特征" class="headerlink" title="代词回指消解所使用的特征"></a>代词回指消解所使用的特征</h3><p>给定代词及代词前面的上下文，从上下文中找出代词的先行词。</p>
<h4 id="用来过滤潜在指代对象的特征"><a href="#用来过滤潜在指代对象的特征" class="headerlink" title="用来过滤潜在指代对象的特征"></a>用来过滤潜在指代对象的特征</h4><p>4 种相关的固定不变的构词特征：</p>
<ul>
<li><p>数的一致（number agreement）：指示和和所指对象在数上保持一致。</p>
</li>
<li><p>人称一致（perosn agreement）：代词的先行词与代词在数上保持一致。</p>
</li>
<li><p>性的一致（gender agreement）：所指对象与指示语的性别保持一致。</p>
</li>
<li><p>约束理论限制（binding theory</p>
<ol>
<li>constraints）：指示语和先行名词短语出现在相同句子中，所指关系受到指示语和先行名词短语之间句法关系的约束。</li>
</ol>
</li>
</ul>
<h4 id="代词解释中的优先关系"><a href="#代词解释中的优先关系" class="headerlink" title="代词解释中的优先关系"></a>代词解释中的优先关系</h4><p>用来预测代词指代对象的特征：</p>
<ul>
<li><p>新近性（recency）：新近的话段所引入的实体比先前较远的话段所引入的实体具有较高的显著性。</p>
</li>
<li><p>语法角色（grammatical role）：通过实体表示的语法位置来排序的实体显著性层级。</p>
<ul>
<li><p>主语位置的实体的显著性最高</p>
</li>
<li><p>宾主位置的实体的显著性其次</p>
</li>
<li><p>后续位置的实体的显著性最低</p>
</li>
</ul>
</li>
<li><p>重复提及（repeated</p>
<ol>
<li>mention）：已经作为焦点的实体，在后面的话语中更可能成为焦点，它们的所指也更可能被代词化。</li>
</ol>
</li>
<li><p>平行（parallelisom）：平行效果会带来明显的优先关系。</p>
</li>
<li><p>动词语义（verb</p>
<ol>
<li>semantics）：动词会对某个位置的论元产生强调，而影响指代优先级。</li>
</ol>
</li>
<li><p>选择限制：语义知识可以影响指代优先级。</p>
</li>
</ul>
<h3 id="代词回指消解的三种算法"><a href="#代词回指消解的三种算法" class="headerlink" title="代词回指消解的三种算法"></a>代词回指消解的三种算法</h3><h4 id="代词回指基准系统：Hobbs-算法"><a href="#代词回指基准系统：Hobbs-算法" class="headerlink" title="代词回指基准系统：Hobbs 算法"></a>代词回指基准系统：Hobbs 算法</h4><p>算法最简单，包括：句法分析器、形态性别检查器和数字检查器，常常用作评价的基准系统。</p>
<p>输入：代词所在句子及代词之前的几个句子的句法表示；</p>
<h4 id="代词回指消解的中心算法"><a href="#代词回指消解的中心算法" class="headerlink" title="代词回指消解的中心算法"></a>代词回指消解的中心算法</h4><p>中心理论（centering<br>theory）显式采用话语模型表示。是实体一致的模型。在话语中的任何给定点都有一个单独的实体被作为“中心”，该实体与被唤起的其他实体有所不同。需要句法分析器和形态性别检查器。</p>
<h4 id="代词回指消解的对数线性模型"><a href="#代词回指消解的对数线性模型" class="headerlink" title="代词回指消解的对数线性模型"></a>代词回指消解的对数线性模型</h4><p>对数线性分类器：基于手工标注的训练语料，语料由标有先行词的代词组成。</p>
<h4 id="代词回指消解的特征"><a href="#代词回指消解的特征" class="headerlink" title="代词回指消解的特征"></a>代词回指消解的特征</h4><ul>
<li><p>严格的数匹配（strict number）：真或假。</p>
</li>
<li><p>相容的数匹配（compatible number）：真或假。</p>
</li>
<li><p>严格的性别匹配（strict gender）：真或假。</p>
</li>
<li><p>相容的性别匹配（compatible gender）：真或假</p>
</li>
<li><p>句子距离（sentence distance）：代词和潜在的先行词之间的句子数目。</p>
</li>
<li><p>Hobbs 距离（Hobbs</p>
<ol>
<li>distance）：从代词开始回溯找到潜在先行词之前，Hobbs 算法必须跳过的名词组的数目。</li>
</ol>
</li>
<li><p>语法角色（grammatical</p>
<ol>
<li>role）：潜在先行词的角色——句法中的主语、直接宾语或者 PP 中的一个嵌入成分。</li>
</ol>
</li>
<li><p>语言学形式（linguistic</p>
<ol>
<li>form）：潜在先行词的形式——专有名词、确定描述、不定描述或者代词。</li>
</ol>
</li>
</ul>
<h3 id="共指消解"><a href="#共指消解" class="headerlink" title="共指消解"></a>共指消解</h3><p>共指消解算法：通过二元分类器，以指代和潜在先行词作为输入，判定是否共指。</p>
<p>共指消解常用特征：</p>
<ul>
<li><p>回指编辑距离（anaphor edit distance）：从潜在先行词到指代的字符最小编辑距离</p>
</li>
<li><p>先行词编辑距离（antecedent edit distance）：从指代到先行词的最小编辑距离</p>
</li>
<li><p>别名（alias）：真或假。命名实体标签的多重特征。</p>
</li>
<li><p>同位语（appositive）：真或假。指代语和先行词是否处于语法中的同位关系。</p>
</li>
<li><p>语言学形式（linguistic</p>
<ol>
<li>form）：潜在回指的形式——专有名称、确定描述、不定描述或者代词。</li>
</ol>
</li>
</ul>
<h3 id="共指消解的评价"><a href="#共指消解的评价" class="headerlink" title="共指消解的评价"></a>共指消解的评价</h3><p>模型理论的共指评价（model-theoretic coreference evaluations）</p>
<p>共指链（reference chain）或真实链（true<br>chain）：是实体出现的正确的或者真实的共指链。</p>
<p>假设链（hypothesis chain）：共指消解算法为实体指派的链或者类。</p>
<p>B-CUBED 算法，评价 MUC-6 方法的扩展，依赖于手工标注的指代短语间的共指语料。计算的是相对于共指链实体在假设链中的准确率和召回率。</p>
<h3 id="基于推理的连贯判定"><a href="#基于推理的连贯判定" class="headerlink" title="基于推理的连贯判定"></a>基于推理的连贯判定</h3><p>假设分析器能够为每个从句指派合理的语义，那么连贯判定方法就可以依靠和每个连贯关系相关的语义限制来执行。</p>
<p>演绎（deduction）就是依赖这些限制进行推理的方法，是向前推出隐含关系的推理方法，是一种可靠推理形式（即前提为真，结论必为真）。</p>
<p>溯因推理或者诱导（abduction）推理：是后向推理方法，即从结果中寻找可能的原因，是不可靠的推理形式，是可以废止的（defeasible），但是提供了更大范围的推理能力。</p>
<p>比较可选择的溯因推理的证据的质量的方法：</p>
<ul>
<li><p>概率模型</p>
</li>
<li><p>启发式策略：优先选择假设数目最少的解释或者最具体的解释</p>
</li>
<li><p>基于代价（cost-based）的策略：结合了概率特征和词性式方法。世界知识和领域知识被用于确定话段间最合理的连贯关系。</p>
</li>
</ul>
<p>注：基于代价的策略可以被应用于语言理解中的许多问题。</p>
<h3 id="所指的心理学研究"><a href="#所指的心理学研究" class="headerlink" title="所指的心理学研究"></a>所指的心理学研究</h3><h3 id="小结-5"><a href="#小结-5" class="headerlink" title="小结"></a>小结</h3><ul>
<li><p>与句子一样，话语也具有层级结构。通过假设话语具有简单的线性结构，可以基于词汇内聚性、话语标志或者提示短语对文本进行主题条件分割。</p>
</li>
<li><p>话语是连贯的。保持话语连贯的因素是句子间的连贯关系以及基于实体的连贯关系。</p>
</li>
<li><p>修辞关系旨连贯关系理论中的一种。用于检测修辞关系的算法可以使用表层提示（例如：提示短语、句法信息）</p>
</li>
<li><p>话语模型：为话语状态建立的一种可以演变的话语表示方式，包含：已经提及的实体和实体之间关系的表示。</p>
</li>
<li><p>指向实体的方法将世界知识集和话语模型一起加工后传递给听话人。</p>
</li>
<li><p>代词所指被用于话语模型中具有足够显著度的所指对象。各种话语的因素都会影响显著性。</p>
</li>
<li><p>Hobbs 算法、中心算法以及对数线性模型提供了不同的方式来使用和结合不同的限制。</p>
</li>
<li><p>完整的 NP 共指任务必须处理名称和确定的 NP。任务中的字符串编辑距离是重要的特征。</p>
</li>
<li><p>建立连贯关系的高级算法使用一个或者多个连贯关系构成的限制，能够推出说话者的潜在信息。不完全的逻辑溯因规则可以用来进行此类推理。</p>
</li>
</ul>
<ol>
<li>自然语言处理的应用</li>
</ol>
<h2 id="信息抽取"><a href="#信息抽取" class="headerlink" title="信息抽取"></a>信息抽取</h2><h2 id="问答-和-摘要"><a href="#问答-和-摘要" class="headerlink" title="问答 和 摘要"></a>问答 和 摘要</h2><h2 id="对话-和-会话智能代理"><a href="#对话-和-会话智能代理" class="headerlink" title="对话 和 会话智能代理"></a>对话 和 会话智能代理</h2><h2 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h2>
</div>

<!-- post-guide -->

    <div class="post-guide">
        <div class="item left">
            
              <a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E3%80%8A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                  <i class="fa fa-angle-left" aria-hidden="true"></i>
                  《自然语言处理》学习笔记
              </a>
            
        </div>
        <div class="item right">
            
              <a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E3%80%8A%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">
                《模式识别与机器学习》的读书笔记
                <i class="fa fa-angle-right" aria-hidden="true"></i>
              </a>
            
        </div>
    </div>


<!-- comment - giscus -->


<!-- comment - valine -->


<script>
	
	
</script>
	</div>
	<div id="footer">
	<p>
	©<span id="footerYear-start"></span>-<span id="footerYear-end"></span>

	
	    <a href="/">ZhuYuanxiang</a>
	
	
	
		|
		<span id="busuanzi_container_site_pv">
			pv
			<span id="busuanzi_value_site_pv"></span>
		</span>
		|
		<span id="busuanzi_container_site_uv"> 
			uv
			<span id="busuanzi_value_site_uv"></span>
		</span>
	
	<br>
	Theme <a href="//github.com/wujun234/hexo-theme-tree" target="_blank">Tree</a>
	by <a href="//wujun.me" target="_blank">Wu Jun</a>
	Powered by <a href="//hexo.io" target="_blank">Hexo</a>
	</p>
</div>


<script type="text/javascript">
	document.getElementById('footerYear-start').innerHTML = new Date().getFullYear() + '';
</script>

<script type="text/javascript">
	document.getElementById('footerYear-end').innerHTML = new Date().getFullYear() + '';
</script>

	<button id="totop-toggle" class="toggle"><i class="fa fa-angle-double-up" aria-hidden="true"></i></button>
</body>
</html>